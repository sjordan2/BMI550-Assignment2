{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "86900f8a-e49a-4bf0-9eda-018787b150af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.data import load\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dadf5b2-59fa-4301-93a5-b6e0cd3cdf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"fallreports_2023-9-21_train.csv\")\n",
    "test_data = pd.read_csv(\"fallreports_2023-9-21_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55654743-2196-429f-b7cd-38a0e8b8cca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>redcap_repeat_instrument</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>education</th>\n",
       "      <th>age_at_enrollment</th>\n",
       "      <th>pd_duration</th>\n",
       "      <th>num_falls_6_mo</th>\n",
       "      <th>previous_falls</th>\n",
       "      <th>...</th>\n",
       "      <th>location_binary</th>\n",
       "      <th>fall_description</th>\n",
       "      <th>fall_class</th>\n",
       "      <th>fog_yn</th>\n",
       "      <th>fall_desc_repeat</th>\n",
       "      <th>aime2023_dataset</th>\n",
       "      <th>last_followup</th>\n",
       "      <th>fall_total</th>\n",
       "      <th>fall_rate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>Fall Report</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Completed college</td>\n",
       "      <td>60</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-faller</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>The patient was hiking. He tripped on an expos...</td>\n",
       "      <td>BoS (slips / trips)</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>378</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>Fall Report</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Completed college</td>\n",
       "      <td>56</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3 or more</td>\n",
       "      <td>faller</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The patient was reaching forward for his phone...</td>\n",
       "      <td>CoM (self-induced or externally-applied)</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>402</td>\n",
       "      <td>231</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>Fall Report</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Completed graduate degree</td>\n",
       "      <td>69</td>\n",
       "      <td>2.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-faller</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>The patient was digging a hole to plant an aza...</td>\n",
       "      <td>BoS (slips / trips)</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>394</td>\n",
       "      <td>8</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>Fall Report</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Completed graduate degree</td>\n",
       "      <td>76</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3 or more</td>\n",
       "      <td>faller</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The patient was walking towards the kitchen ta...</td>\n",
       "      <td>CoM (self-induced or externally-applied)</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>96</td>\n",
       "      <td>480</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>Fall Report</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Completed graduate degree</td>\n",
       "      <td>56</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "      <td>faller</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>The patient was home playing catch in backyard...</td>\n",
       "      <td>Unclassifiable (falls from bed, sports-related...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>391</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>16</td>\n",
       "      <td>Fall Report</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Completed high school</td>\n",
       "      <td>64</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3 or more</td>\n",
       "      <td>faller</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The patient was in the living room trying to s...</td>\n",
       "      <td>CoM (self-induced or externally-applied)</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>371</td>\n",
       "      <td>12</td>\n",
       "      <td>0.032345</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>122</td>\n",
       "      <td>Fall Report</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Completed graduate degree</td>\n",
       "      <td>65</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1</td>\n",
       "      <td>faller</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>The patient was at the supermarket. He took on...</td>\n",
       "      <td>CoM (self-induced or externally-applied)</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>383</td>\n",
       "      <td>8</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>39</td>\n",
       "      <td>Fall Report</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Completed graduate degree</td>\n",
       "      <td>76</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3 or more</td>\n",
       "      <td>faller</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The patient was walking to the kitchen counter...</td>\n",
       "      <td>CoM (self-induced or externally-applied)</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>96</td>\n",
       "      <td>480</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>56</td>\n",
       "      <td>Fall Report</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Completed junior college (associate's degree, ...</td>\n",
       "      <td>65</td>\n",
       "      <td>15.7</td>\n",
       "      <td>3 or more</td>\n",
       "      <td>faller</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The patient was in their bathroom and there wa...</td>\n",
       "      <td>BoS (slips / trips)</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>380</td>\n",
       "      <td>37</td>\n",
       "      <td>0.097368</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>39</td>\n",
       "      <td>Fall Report</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Completed graduate degree</td>\n",
       "      <td>76</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3 or more</td>\n",
       "      <td>faller</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The patient was walking toward the counter wit...</td>\n",
       "      <td>CoM (self-induced or externally-applied)</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>96</td>\n",
       "      <td>480</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id redcap_repeat_instrument  gender   race  \\\n",
       "0           66              Fall Report    Male  White   \n",
       "1           28              Fall Report    Male  White   \n",
       "2           57              Fall Report    Male  White   \n",
       "3           39              Fall Report    Male  White   \n",
       "4           55              Fall Report    Male  White   \n",
       "..         ...                      ...     ...    ...   \n",
       "294         16              Fall Report  Female  White   \n",
       "295        122              Fall Report    Male  White   \n",
       "296         39              Fall Report    Male  White   \n",
       "297         56              Fall Report  Female  White   \n",
       "298         39              Fall Report    Male  White   \n",
       "\n",
       "                  ethnicity  \\\n",
       "0    Not Hispanic or Latino   \n",
       "1    Not Hispanic or Latino   \n",
       "2    Not Hispanic or Latino   \n",
       "3    Not Hispanic or Latino   \n",
       "4    Not Hispanic or Latino   \n",
       "..                      ...   \n",
       "294  Not Hispanic or Latino   \n",
       "295  Not Hispanic or Latino   \n",
       "296  Not Hispanic or Latino   \n",
       "297  Not Hispanic or Latino   \n",
       "298  Not Hispanic or Latino   \n",
       "\n",
       "                                             education  age_at_enrollment  \\\n",
       "0                                    Completed college                 60   \n",
       "1                                    Completed college                 56   \n",
       "2                            Completed graduate degree                 69   \n",
       "3                            Completed graduate degree                 76   \n",
       "4                            Completed graduate degree                 56   \n",
       "..                                                 ...                ...   \n",
       "294                              Completed high school                 64   \n",
       "295                          Completed graduate degree                 65   \n",
       "296                          Completed graduate degree                 76   \n",
       "297  Completed junior college (associate's degree, ...                 65   \n",
       "298                          Completed graduate degree                 76   \n",
       "\n",
       "     pd_duration num_falls_6_mo previous_falls  ...  location_binary  \\\n",
       "0            2.4            NaN     non-faller  ...               No   \n",
       "1            8.0      3 or more         faller  ...              Yes   \n",
       "2            2.7            NaN     non-faller  ...               No   \n",
       "3            9.7      3 or more         faller  ...              Yes   \n",
       "4            9.8              1         faller  ...               No   \n",
       "..           ...            ...            ...  ...              ...   \n",
       "294          7.9      3 or more         faller  ...              Yes   \n",
       "295          7.1              1         faller  ...               No   \n",
       "296          9.7      3 or more         faller  ...              Yes   \n",
       "297         15.7      3 or more         faller  ...              Yes   \n",
       "298          9.7      3 or more         faller  ...              Yes   \n",
       "\n",
       "                                      fall_description  \\\n",
       "0    The patient was hiking. He tripped on an expos...   \n",
       "1    The patient was reaching forward for his phone...   \n",
       "2    The patient was digging a hole to plant an aza...   \n",
       "3    The patient was walking towards the kitchen ta...   \n",
       "4    The patient was home playing catch in backyard...   \n",
       "..                                                 ...   \n",
       "294  The patient was in the living room trying to s...   \n",
       "295  The patient was at the supermarket. He took on...   \n",
       "296  The patient was walking to the kitchen counter...   \n",
       "297  The patient was in their bathroom and there wa...   \n",
       "298  The patient was walking toward the counter wit...   \n",
       "\n",
       "                                            fall_class  fog_yn  \\\n",
       "0                                  BoS (slips / trips)      No   \n",
       "1             CoM (self-induced or externally-applied)      No   \n",
       "2                                  BoS (slips / trips)      No   \n",
       "3             CoM (self-induced or externally-applied)      No   \n",
       "4    Unclassifiable (falls from bed, sports-related...      No   \n",
       "..                                                 ...     ...   \n",
       "294           CoM (self-induced or externally-applied)      No   \n",
       "295           CoM (self-induced or externally-applied)      No   \n",
       "296           CoM (self-induced or externally-applied)      No   \n",
       "297                                BoS (slips / trips)      No   \n",
       "298           CoM (self-induced or externally-applied)      No   \n",
       "\n",
       "     fall_desc_repeat  aime2023_dataset  last_followup  fall_total fall_rate  \\\n",
       "0                  No               Yes            378           1  0.002646   \n",
       "1                  No                No            402         231  0.574627   \n",
       "2                  No               Yes            394           8  0.020305   \n",
       "3                  No               Yes             96         480  5.000000   \n",
       "4                  No               Yes            391           2  0.005115   \n",
       "..                ...               ...            ...         ...       ...   \n",
       "294                No               Yes            371          12  0.032345   \n",
       "295                No               Yes            383           8  0.020888   \n",
       "296                No               Yes             96         480  5.000000   \n",
       "297                No                No            380          37  0.097368   \n",
       "298                No               Yes             96         480  5.000000   \n",
       "\n",
       "    category  \n",
       "0      train  \n",
       "1      train  \n",
       "2      train  \n",
       "3      train  \n",
       "4      train  \n",
       "..       ...  \n",
       "294    train  \n",
       "295    train  \n",
       "296    train  \n",
       "297    train  \n",
       "298    train  \n",
       "\n",
       "[299 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac18fe25-e3da-4e9d-91ab-84a31083b4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['faller', 'non-faller'], dtype=object), array([279,  20]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_data[\"previous_falls\"], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca5c94d-6058-4eb8-abc5-29632a26400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop([\"fog_q_class\", \"fog_yn\", \"category\", \"record_id\"], axis=1)[\"fall_description\"].to_numpy()\n",
    "y_train = train_data[\"fog_q_class\"].to_numpy()\n",
    "\n",
    "X_test = test_data.drop([\"fog_q_class\", \"fog_yn\", \"category\", \"record_id\"], axis=1)[\"fall_description\"].to_numpy()\n",
    "y_test = test_data[\"fog_q_class\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c835b5-22de-4e3f-8482-3653fba944ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some descriptions were reported as NaN, so I removed them from the dataset\n",
    "\n",
    "nan_descriptions = []\n",
    "for obj_index in range(len(X_train)):\n",
    "    obj = X_train[obj_index]\n",
    "    if type(obj) == float:\n",
    "        nan_descriptions.append(obj_index)\n",
    "\n",
    "X_train = np.delete(X_train, nan_descriptions)\n",
    "y_train = np.delete(y_train, nan_descriptions)\n",
    "\n",
    "nan_descriptions_test = []\n",
    "for obj_index in range(len(X_test)):\n",
    "    obj = X_test[obj_index]\n",
    "    if type(obj) == float:\n",
    "        nan_descriptions_test.append(obj_index)\n",
    "\n",
    "X_test = np.delete(X_test, nan_descriptions_test)\n",
    "y_test = np.delete(y_test, nan_descriptions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f831cb1b-e2cf-423a-a199-f4d8cad1d4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([92, 140, 234], dtype='int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.index[nan_descriptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b97b7c63-d145-4c26-a39b-9969cc63ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(train_data.index[nan_descriptions])\n",
    "test_data = test_data.drop(test_data.index[nan_descriptions_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e75bbd55-d1d2-47dc-b46b-800a110df2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['num_characters'] = train_data.apply(lambda row : len(row[\"fall_description\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9227a843-8df0-4062-a41f-3d6949ce7435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      128\n",
       "1      150\n",
       "2      528\n",
       "3      160\n",
       "4      194\n",
       "      ... \n",
       "294    128\n",
       "295    235\n",
       "296    310\n",
       "297    444\n",
       "298    227\n",
       "Name: num_characters, Length: 296, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['num_characters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3852ee9d-4bcf-4039-bb95-889b402cad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['avg_word_length'] = train_data.apply(lambda row: np.mean([len(word) for word in row[\"fall_description\"].split()]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "403a651d-13cc-47b0-b80a-57a583aae3a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.777778\n",
       "1      4.392857\n",
       "2      4.057692\n",
       "3      4.366667\n",
       "4      4.571429\n",
       "         ...   \n",
       "294    3.777778\n",
       "295    3.916667\n",
       "296    4.183333\n",
       "297    4.056818\n",
       "298    4.560976\n",
       "Name: avg_word_length, Length: 296, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['avg_word_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "87e5e8b3-526f-4abf-b945-84e6ed40a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a custom \"classifier\" to handle data transformation... this is required so there is no train/test leakage through vectorized text\n",
    "# This will be put through a scikit-learn pipeline, which allows it to be used correctly with a hyperparameter search and cross validation\n",
    "class FreezingOfGaitDatasetBuilder():\n",
    "    def __init__(self, preprocess=True):\n",
    "        self.tf_idf_vectorizer = None\n",
    "        self.ngram_vectorizer = None\n",
    "        self.word2vec_model = None\n",
    "        self.preprocess = preprocess\n",
    "    \n",
    "    def transform(self, input_df, **transform_params):\n",
    "        word_embeddings = None\n",
    "        new_tfidf_data = None\n",
    "        new_ngram_data = None\n",
    "        \n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "        \n",
    "            # Word2Vec data\n",
    "            word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df_new])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            new_tfidf_data = self.tf_idf_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            new_ngram_data = self.ngram_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "\n",
    "        else:\n",
    "            # Word2Vec data\n",
    "            word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df[\"fall_description\"]])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            new_tfidf_data = self.tf_idf_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            new_ngram_data = self.ngram_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "\n",
    "        # Number of characters data\n",
    "        input_df['num_characters'] = input_df.apply(lambda row : len(row[\"fall_description\"]), axis = 1)\n",
    "        num_chars = input_df['num_characters'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # Average length of words data\n",
    "        input_df['avg_word_length'] = input_df.apply(lambda row: np.mean([len(word) for word in row[\"fall_description\"].split()]), axis=1)\n",
    "        avg_length = input_df['avg_word_length'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # Parts of speech data\n",
    "        pos_tag_counts = input_df.apply(lambda row: self.pos_tagger_func(row), axis = 1)\n",
    "        pos_tag_array = pos_tag_counts[[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"]].to_numpy()\n",
    "    \n",
    "        pre_finalized_data = np.hstack((word_embeddings, new_tfidf_data, new_ngram_data, num_chars, avg_length, pos_tag_array))\n",
    "        standard_scaler = StandardScaler()\n",
    "        finalized_data = standard_scaler.fit_transform(pre_finalized_data)\n",
    "        return finalized_data\n",
    "    \n",
    "    def fit(self, input_df, y=None, **fit_params):\n",
    "        sentences = None\n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "            sentences = [sentence.split() for sentence in input_df_new]\n",
    "            self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            self.tf_idf_vectorizer.fit(input_df_new.to_numpy())\n",
    "            self.ngram_vectorizer.fit(input_df_new.to_numpy())\n",
    "        else:\n",
    "            sentences = [sentence.split() for sentence in input_df[\"fall_description\"]]\n",
    "            self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            self.tf_idf_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "            self.ngram_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, input_df, y=None, **fit_transform_params):\n",
    "        self.fit(input_df)\n",
    "        return self.transform(input_df)\n",
    "\n",
    "    def pos_tagger_func(self, row):\n",
    "        fall_description = row[\"fall_description\"]\n",
    "        word_tokens = word_tokenize(fall_description)\n",
    "        tagged_words = pos_tag(word_tokens)\n",
    "        list_of_tags = [tag[1] for tag in tagged_words] # Just get list of tags\n",
    "        # The POS tagger has a lot of possible tags, but since we don't want to increase dimensionality too much, we will condense this a bit\n",
    "        # Inspiration taken from https://betterprogramming.pub/beginners-to-advanced-feature-engineering-from-text-data-c228047a4813\n",
    "        noun_count = 0\n",
    "        pronoun_count = 0\n",
    "        verb_count = 0\n",
    "        adj_count = 0\n",
    "        numeric_count = 0\n",
    "        \n",
    "        for tag in list_of_tags:\n",
    "            if tag in ['NN','NNP','NNS']:\n",
    "                noun_count += 1\n",
    "            elif tag in ['PRP','PRP$']:\n",
    "                pronoun_count += 1\n",
    "            elif tag in ['VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "                verb_count += 1\n",
    "            elif tag in ['JJ','JJR','JJS']:\n",
    "                adj_count += 1\n",
    "            elif tag in ['CD']:\n",
    "                numeric_count += 1\n",
    "            # Not including else for other annotations because then it could throw the model training off track\n",
    "        return pd.Series([noun_count / len(list_of_tags), pronoun_count / len(list_of_tags), verb_count / len(list_of_tags), \n",
    "                          adj_count / len(list_of_tags), numeric_count / len(list_of_tags)], \n",
    "                         index=[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"])\n",
    "\n",
    "    def preprocess_text_data(self, text):\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        text = text.lower()\n",
    "        text = ''.join([word for word in text if word not in string.punctuation])\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def vectorize(self, sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [self.word2vec_model.wv[word] for word in words if word in self.word2vec_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c04ce429-d75a-4dee-b719-1fb65f4d51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing custom classifier\n",
    "fog_db = FreezingOfGaitDatasetBuilder(preprocess=False)\n",
    "fog_db.fit(train_data)\n",
    "new_data = fog_db.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "47fc2fda-853e-426c-896b-a638b8a4254d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ...gaussiannb__var_smoothing=1e-09;, score=0.733 total time=   0.9s\n",
      "[CV 2/5] END ...gaussiannb__var_smoothing=1e-09;, score=0.831 total time=   0.9s\n",
      "[CV 3/5] END ...gaussiannb__var_smoothing=1e-09;, score=0.763 total time=   0.9s\n",
      "[CV 4/5] END ...gaussiannb__var_smoothing=1e-09;, score=0.712 total time=   0.9s\n",
      "[CV 5/5] END ...gaussiannb__var_smoothing=1e-09;, score=0.797 total time=   0.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337e83160&gt;),\n",
       "                                       (&#x27;gaussiannb&#x27;, GaussianNB())]),\n",
       "             param_grid={&#x27;gaussiannb__var_smoothing&#x27;: [1e-09]}, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337e83160&gt;),\n",
       "                                       (&#x27;gaussiannb&#x27;, GaussianNB())]),\n",
       "             param_grid={&#x27;gaussiannb__var_smoothing&#x27;: [1e-09]}, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                 &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337e83160&gt;),\n",
       "                (&#x27;gaussiannb&#x27;, GaussianNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FreezingOfGaitDatasetBuilder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337e83160&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=Pipeline(steps=[('freezingofgaitdatasetbuilder',\n",
       "                                        <__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337e83160>),\n",
       "                                       ('gaussiannb', GaussianNB())]),\n",
       "             param_grid={'gaussiannb__var_smoothing': [1e-09]}, verbose=3)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "nb_classifier_true = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=True), GaussianNB())\n",
    "\n",
    "nb_cross_val_true = GridSearchCV(nb_classifier_true, {\"gaussiannb__var_smoothing\": [1e-9]}, verbose = 3, error_score=\"raise\")\n",
    "\n",
    "nb_cross_val_true.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ae034c70-ad5c-4966-ab1f-a0655cd6fa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ...gaussiannb__var_smoothing=1e-09;, score=0.733 total time=   0.8s\n",
      "[CV 2/5] END ...gaussiannb__var_smoothing=1e-09;, score=0.864 total time=   0.8s\n",
      "[CV 3/5] END ...gaussiannb__var_smoothing=1e-09;, score=0.729 total time=   0.8s\n",
      "[CV 4/5] END ...gaussiannb__var_smoothing=1e-09;, score=0.814 total time=   0.8s\n",
      "[CV 5/5] END ...gaussiannb__var_smoothing=1e-09;, score=0.831 total time=   0.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff3526ac0d0&gt;),\n",
       "                                       (&#x27;gaussiannb&#x27;, GaussianNB())]),\n",
       "             param_grid={&#x27;gaussiannb__var_smoothing&#x27;: [1e-09]}, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff3526ac0d0&gt;),\n",
       "                                       (&#x27;gaussiannb&#x27;, GaussianNB())]),\n",
       "             param_grid={&#x27;gaussiannb__var_smoothing&#x27;: [1e-09]}, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                 &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff3526ac0d0&gt;),\n",
       "                (&#x27;gaussiannb&#x27;, GaussianNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FreezingOfGaitDatasetBuilder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff3526ac0d0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=Pipeline(steps=[('freezingofgaitdatasetbuilder',\n",
       "                                        <__main__.FreezingOfGaitDatasetBuilder object at 0x7ff3526ac0d0>),\n",
       "                                       ('gaussiannb', GaussianNB())]),\n",
       "             param_grid={'gaussiannb__var_smoothing': [1e-09]}, verbose=3)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "nb_classifier_false = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), GaussianNB())\n",
    "\n",
    "nb_cross_val_false = GridSearchCV(nb_classifier_false, {\"gaussiannb__var_smoothing\": [1e-9]}, verbose = 3, error_score=\"raise\")\n",
    "\n",
    "nb_cross_val_false.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "93ef05a9-0322-4037-b46e-77b6e19de471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Naive Bayes Score with Preprocessing: 0.7670056497175142\n",
      "Best Naive Bayes Score without Preprocessing: 0.7941242937853107\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Naive Bayes Score with Preprocessing:\", nb_cross_val_true.best_score_)\n",
    "print(\"Best Naive Bayes Score without Preprocessing:\", nb_cross_val_false.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "56d8ae5f-c681-4ed7-9602-3cd5597951f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score: 0.7971\n",
      "Naive Bayes Macro-Averaged F1 Score: 0.7936\n",
      "Naive Bayes Micro-Averaged F1 Score: 0.7971\n"
     ]
    }
   ],
   "source": [
    "final_nb_classifier = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), GaussianNB())\n",
    "final_nb_classifier.fit(train_data, y_train)\n",
    "y_pred = final_nb_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_nb = f1_score(y_test, y_pred, average=\"micro\")\n",
    "macro_f1_score_nb = f1_score(y_test, y_pred, average=\"macro\")\n",
    "accuracy_score_nb = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Naive Bayes Accuracy Score:\", round(accuracy_score_nb, 4))\n",
    "print(\"Naive Bayes Macro-Averaged F1 Score:\", round(macro_f1_score_nb, 4))\n",
    "print(\"Naive Bayes Micro-Averaged F1 Score:\", round(micro_f1_score_nb, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d6744a89-e2ea-478b-ac80-eaf7f615bdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END svc__C=0.1, svc__kernel=rbf, svc__probability=True;, score=0.517 total time=   1.8s\n",
      "[CV 2/5] END svc__C=0.1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   1.7s\n",
      "[CV 3/5] END svc__C=0.1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   1.7s\n",
      "[CV 4/5] END svc__C=0.1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   1.7s\n",
      "[CV 5/5] END svc__C=0.1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   5.4s\n",
      "[CV 1/5] END svc__C=0.1, svc__kernel=poly, svc__probability=True;, score=0.517 total time=   1.6s\n",
      "[CV 2/5] END svc__C=0.1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 3/5] END svc__C=0.1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 4/5] END svc__C=0.1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 5/5] END svc__C=0.1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   4.4s\n",
      "[CV 1/5] END svc__C=0.1, svc__kernel=sigmoid, svc__probability=True;, score=0.517 total time=   1.6s\n",
      "[CV 2/5] END svc__C=0.1, svc__kernel=sigmoid, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 3/5] END svc__C=0.1, svc__kernel=sigmoid, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 4/5] END svc__C=0.1, svc__kernel=sigmoid, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 5/5] END svc__C=0.1, svc__kernel=sigmoid, svc__probability=True;, score=0.525 total time=   4.6s\n",
      "[CV 1/5] END svc__C=1, svc__kernel=rbf, svc__probability=True;, score=0.517 total time=   1.8s\n",
      "[CV 2/5] END svc__C=1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   1.7s\n",
      "[CV 3/5] END svc__C=1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   1.7s\n",
      "[CV 4/5] END svc__C=1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   1.7s\n",
      "[CV 5/5] END svc__C=1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   6.1s\n",
      "[CV 1/5] END svc__C=1, svc__kernel=poly, svc__probability=True;, score=0.517 total time=   1.6s\n",
      "[CV 2/5] END svc__C=1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 3/5] END svc__C=1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 4/5] END svc__C=1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 5/5] END svc__C=1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   5.2s\n",
      "[CV 1/5] END svc__C=1, svc__kernel=sigmoid, svc__probability=True;, score=0.733 total time=   1.7s\n",
      "[CV 2/5] END svc__C=1, svc__kernel=sigmoid, svc__probability=True;, score=0.712 total time=   1.6s\n",
      "[CV 3/5] END svc__C=1, svc__kernel=sigmoid, svc__probability=True;, score=0.797 total time=   1.5s\n",
      "[CV 4/5] END svc__C=1, svc__kernel=sigmoid, svc__probability=True;, score=0.763 total time=   1.5s\n",
      "[CV 5/5] END svc__C=1, svc__kernel=sigmoid, svc__probability=True;, score=0.797 total time=   5.2s\n",
      "[CV 1/5] END svc__C=10, svc__kernel=rbf, svc__probability=True;, score=0.517 total time=   1.8s\n",
      "[CV 2/5] END svc__C=10, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   1.7s\n",
      "[CV 3/5] END svc__C=10, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   1.7s\n",
      "[CV 4/5] END svc__C=10, svc__kernel=rbf, svc__probability=True;, score=0.542 total time=   1.7s\n",
      "[CV 5/5] END svc__C=10, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   6.7s\n",
      "[CV 1/5] END svc__C=10, svc__kernel=poly, svc__probability=True;, score=0.517 total time=   1.6s\n",
      "[CV 2/5] END svc__C=10, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 3/5] END svc__C=10, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 4/5] END svc__C=10, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 5/5] END svc__C=10, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   5.4s\n",
      "[CV 1/5] END svc__C=10, svc__kernel=sigmoid, svc__probability=True;, score=0.800 total time=   1.6s\n",
      "[CV 2/5] END svc__C=10, svc__kernel=sigmoid, svc__probability=True;, score=0.831 total time=   1.5s\n",
      "[CV 3/5] END svc__C=10, svc__kernel=sigmoid, svc__probability=True;, score=0.780 total time=   1.5s\n",
      "[CV 4/5] END svc__C=10, svc__kernel=sigmoid, svc__probability=True;, score=0.746 total time=   1.5s\n",
      "[CV 5/5] END svc__C=10, svc__kernel=sigmoid, svc__probability=True;, score=0.814 total time=   5.4s\n",
      "[CV 1/5] END svc__C=100, svc__kernel=rbf, svc__probability=True;, score=0.517 total time=   1.8s\n",
      "[CV 2/5] END svc__C=100, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   1.7s\n",
      "[CV 3/5] END svc__C=100, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   1.7s\n",
      "[CV 4/5] END svc__C=100, svc__kernel=rbf, svc__probability=True;, score=0.542 total time=   1.7s\n",
      "[CV 5/5] END svc__C=100, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   7.6s\n",
      "[CV 1/5] END svc__C=100, svc__kernel=poly, svc__probability=True;, score=0.517 total time=   1.6s\n",
      "[CV 2/5] END svc__C=100, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 3/5] END svc__C=100, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 4/5] END svc__C=100, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   1.5s\n",
      "[CV 5/5] END svc__C=100, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   5.5s\n",
      "[CV 1/5] END svc__C=100, svc__kernel=sigmoid, svc__probability=True;, score=0.800 total time=   1.6s\n",
      "[CV 2/5] END svc__C=100, svc__kernel=sigmoid, svc__probability=True;, score=0.831 total time=   1.5s\n",
      "[CV 3/5] END svc__C=100, svc__kernel=sigmoid, svc__probability=True;, score=0.780 total time=   1.5s\n",
      "[CV 4/5] END svc__C=100, svc__kernel=sigmoid, svc__probability=True;, score=0.746 total time=   1.5s\n",
      "[CV 5/5] END svc__C=100, svc__kernel=sigmoid, svc__probability=True;, score=0.814 total time=   5.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d37730&gt;),\n",
       "                                       (&#x27;svc&#x27;, SVC())]),\n",
       "             param_grid={&#x27;svc__C&#x27;: [0.1, 1, 10, 100],\n",
       "                         &#x27;svc__kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;],\n",
       "                         &#x27;svc__probability&#x27;: [True]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d37730&gt;),\n",
       "                                       (&#x27;svc&#x27;, SVC())]),\n",
       "             param_grid={&#x27;svc__C&#x27;: [0.1, 1, 10, 100],\n",
       "                         &#x27;svc__kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;],\n",
       "                         &#x27;svc__probability&#x27;: [True]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                 &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d37730&gt;),\n",
       "                (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FreezingOfGaitDatasetBuilder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d37730&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=Pipeline(steps=[('freezingofgaitdatasetbuilder',\n",
       "                                        <__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d37730>),\n",
       "                                       ('svc', SVC())]),\n",
       "             param_grid={'svc__C': [0.1, 1, 10, 100],\n",
       "                         'svc__kernel': ['rbf', 'poly', 'sigmoid'],\n",
       "                         'svc__probability': [True]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC Classifier\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "svc_classifier_true = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=True), SVC())\n",
    "\n",
    "svc_cross_val_true = GridSearchCV(svc_classifier_true, {\"svc__C\": [0.1, 1, 10, 100], \"svc__kernel\": ['rbf', 'poly', 'sigmoid'], \"svc__probability\": [True]}, verbose = 3, error_score=\"raise\")\n",
    "\n",
    "svc_cross_val_true.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "05c1ac28-3ace-4022-9b14-f4cdddce86a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END svc__C=0.1, svc__kernel=rbf, svc__probability=True;, score=0.517 total time=   6.8s\n",
      "[CV 2/5] END svc__C=0.1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   7.3s\n",
      "[CV 3/5] END svc__C=0.1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   7.4s\n",
      "[CV 4/5] END svc__C=0.1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   7.6s\n",
      "[CV 5/5] END svc__C=0.1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   8.0s\n",
      "[CV 1/5] END svc__C=0.1, svc__kernel=poly, svc__probability=True;, score=0.517 total time=   5.8s\n",
      "[CV 2/5] END svc__C=0.1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   5.9s\n",
      "[CV 3/5] END svc__C=0.1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   5.9s\n",
      "[CV 4/5] END svc__C=0.1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   6.0s\n",
      "[CV 5/5] END svc__C=0.1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   3.7s\n",
      "[CV 1/5] END svc__C=0.1, svc__kernel=sigmoid, svc__probability=True;, score=0.517 total time=   4.6s\n",
      "[CV 2/5] END svc__C=0.1, svc__kernel=sigmoid, svc__probability=True;, score=0.525 total time=   5.0s\n",
      "[CV 3/5] END svc__C=0.1, svc__kernel=sigmoid, svc__probability=True;, score=0.525 total time=   4.6s\n",
      "[CV 4/5] END svc__C=0.1, svc__kernel=sigmoid, svc__probability=True;, score=0.525 total time=   4.9s\n",
      "[CV 5/5] END svc__C=0.1, svc__kernel=sigmoid, svc__probability=True;, score=0.525 total time=   5.0s\n",
      "[CV 1/5] END svc__C=1, svc__kernel=rbf, svc__probability=True;, score=0.517 total time=   7.0s\n",
      "[CV 2/5] END svc__C=1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   7.4s\n",
      "[CV 3/5] END svc__C=1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   7.6s\n",
      "[CV 4/5] END svc__C=1, svc__kernel=rbf, svc__probability=True;, score=0.542 total time=   7.4s\n",
      "[CV 5/5] END svc__C=1, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   5.6s\n",
      "[CV 1/5] END svc__C=1, svc__kernel=poly, svc__probability=True;, score=0.517 total time=   4.6s\n",
      "[CV 2/5] END svc__C=1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   4.6s\n",
      "[CV 3/5] END svc__C=1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   4.5s\n",
      "[CV 4/5] END svc__C=1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   5.4s\n",
      "[CV 5/5] END svc__C=1, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   4.9s\n",
      "[CV 1/5] END svc__C=1, svc__kernel=sigmoid, svc__probability=True;, score=0.783 total time=   4.7s\n",
      "[CV 2/5] END svc__C=1, svc__kernel=sigmoid, svc__probability=True;, score=0.797 total time=   4.9s\n",
      "[CV 3/5] END svc__C=1, svc__kernel=sigmoid, svc__probability=True;, score=0.797 total time=   5.2s\n",
      "[CV 4/5] END svc__C=1, svc__kernel=sigmoid, svc__probability=True;, score=0.797 total time=   5.3s\n",
      "[CV 5/5] END svc__C=1, svc__kernel=sigmoid, svc__probability=True;, score=0.864 total time=   5.3s\n",
      "[CV 1/5] END svc__C=10, svc__kernel=rbf, svc__probability=True;, score=0.517 total time=   7.6s\n",
      "[CV 2/5] END svc__C=10, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   7.5s\n",
      "[CV 3/5] END svc__C=10, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   7.3s\n",
      "[CV 4/5] END svc__C=10, svc__kernel=rbf, svc__probability=True;, score=0.559 total time=   6.2s\n",
      "[CV 5/5] END svc__C=10, svc__kernel=rbf, svc__probability=True;, score=0.542 total time=   6.6s\n",
      "[CV 1/5] END svc__C=10, svc__kernel=poly, svc__probability=True;, score=0.517 total time=   4.6s\n",
      "[CV 2/5] END svc__C=10, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   4.2s\n",
      "[CV 3/5] END svc__C=10, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   4.3s\n",
      "[CV 4/5] END svc__C=10, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   4.4s\n",
      "[CV 5/5] END svc__C=10, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   4.4s\n",
      "[CV 1/5] END svc__C=10, svc__kernel=sigmoid, svc__probability=True;, score=0.883 total time=   4.3s\n",
      "[CV 2/5] END svc__C=10, svc__kernel=sigmoid, svc__probability=True;, score=0.797 total time=   4.5s\n",
      "[CV 3/5] END svc__C=10, svc__kernel=sigmoid, svc__probability=True;, score=0.831 total time=   4.4s\n",
      "[CV 4/5] END svc__C=10, svc__kernel=sigmoid, svc__probability=True;, score=0.814 total time=   4.2s\n",
      "[CV 5/5] END svc__C=10, svc__kernel=sigmoid, svc__probability=True;, score=0.881 total time=   4.4s\n",
      "[CV 1/5] END svc__C=100, svc__kernel=rbf, svc__probability=True;, score=0.517 total time=   6.6s\n",
      "[CV 2/5] END svc__C=100, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   6.5s\n",
      "[CV 3/5] END svc__C=100, svc__kernel=rbf, svc__probability=True;, score=0.525 total time=   5.4s\n",
      "[CV 4/5] END svc__C=100, svc__kernel=rbf, svc__probability=True;, score=0.559 total time=   5.6s\n",
      "[CV 5/5] END svc__C=100, svc__kernel=rbf, svc__probability=True;, score=0.542 total time=   5.8s\n",
      "[CV 1/5] END svc__C=100, svc__kernel=poly, svc__probability=True;, score=0.517 total time=   4.1s\n",
      "[CV 2/5] END svc__C=100, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   4.1s\n",
      "[CV 3/5] END svc__C=100, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   4.2s\n",
      "[CV 4/5] END svc__C=100, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   3.8s\n",
      "[CV 5/5] END svc__C=100, svc__kernel=poly, svc__probability=True;, score=0.525 total time=   3.8s\n",
      "[CV 1/5] END svc__C=100, svc__kernel=sigmoid, svc__probability=True;, score=0.883 total time=   3.7s\n",
      "[CV 2/5] END svc__C=100, svc__kernel=sigmoid, svc__probability=True;, score=0.797 total time=   3.8s\n",
      "[CV 3/5] END svc__C=100, svc__kernel=sigmoid, svc__probability=True;, score=0.831 total time=   4.0s\n",
      "[CV 4/5] END svc__C=100, svc__kernel=sigmoid, svc__probability=True;, score=0.814 total time=   3.9s\n",
      "[CV 5/5] END svc__C=100, svc__kernel=sigmoid, svc__probability=True;, score=0.881 total time=   4.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337e832e0&gt;),\n",
       "                                       (&#x27;svc&#x27;, SVC())]),\n",
       "             param_grid={&#x27;svc__C&#x27;: [0.1, 1, 10, 100],\n",
       "                         &#x27;svc__kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;],\n",
       "                         &#x27;svc__probability&#x27;: [True]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337e832e0&gt;),\n",
       "                                       (&#x27;svc&#x27;, SVC())]),\n",
       "             param_grid={&#x27;svc__C&#x27;: [0.1, 1, 10, 100],\n",
       "                         &#x27;svc__kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;],\n",
       "                         &#x27;svc__probability&#x27;: [True]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                 &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337e832e0&gt;),\n",
       "                (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FreezingOfGaitDatasetBuilder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337e832e0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=Pipeline(steps=[('freezingofgaitdatasetbuilder',\n",
       "                                        <__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337e832e0>),\n",
       "                                       ('svc', SVC())]),\n",
       "             param_grid={'svc__C': [0.1, 1, 10, 100],\n",
       "                         'svc__kernel': ['rbf', 'poly', 'sigmoid'],\n",
       "                         'svc__probability': [True]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC Classifier\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "svc_classifier_false = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), SVC())\n",
    "\n",
    "svc_cross_val_false = GridSearchCV(svc_classifier_false, {\"svc__C\": [0.1, 1, 10, 100], \"svc__kernel\": ['rbf', 'poly', 'sigmoid'], \"svc__probability\": [True]}, verbose = 3, error_score=\"raise\")\n",
    "\n",
    "svc_cross_val_false.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6c9d89a8-6377-45b7-9e41-779f837191c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVC Score with Preprocessing: 0.7938983050847457\n",
      "Best SVC Parameters with Preprocessing: {'svc__C': 10, 'svc__kernel': 'sigmoid', 'svc__probability': True}\n",
      "Best SVC Score without Preprocessing: 0.8410734463276837\n",
      "Best SVC Parameters without Preprocessing: {'svc__C': 10, 'svc__kernel': 'sigmoid', 'svc__probability': True}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best SVC Score with Preprocessing:\", svc_cross_val_true.best_score_)\n",
    "print(\"Best SVC Parameters with Preprocessing:\", svc_cross_val_true.best_params_)\n",
    "print(\"Best SVC Score without Preprocessing:\", svc_cross_val_false.best_score_)\n",
    "print(\"Best SVC Parameters without Preprocessing:\", svc_cross_val_false.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1d3f31a4-5fa7-4f9e-880a-1cbd579d498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy Score: 0.8116\n",
      "SVC Macro-Averaged F1 Score: 0.8116\n",
      "SVC Micro-Averaged F1 Score: 0.8116\n"
     ]
    }
   ],
   "source": [
    "final_svc_classifier = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), SVC(C=10, kernel=\"sigmoid\", probability=True))\n",
    "final_svc_classifier.fit(train_data, y_train)\n",
    "y_pred = final_svc_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_svc = f1_score(y_test, y_pred, average=\"micro\")\n",
    "macro_f1_score_svc = f1_score(y_test, y_pred, average=\"macro\")\n",
    "accuracy_score_svc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"SVC Accuracy Score:\", round(accuracy_score_svc, 4))\n",
    "print(\"SVC Macro-Averaged F1 Score:\", round(macro_f1_score_svc, 4))\n",
    "print(\"SVC Micro-Averaged F1 Score:\", round(micro_f1_score_svc, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "63ddff0c-5ab3-4c76-a074-d27aa0b9fbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.717 total time=  19.7s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.746 total time=  18.6s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.729 total time=  19.3s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.593 total time=  20.2s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.763 total time=  22.2s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.783 total time=   5.8s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.780 total time=   4.9s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.780 total time=   4.7s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.763 total time=   4.5s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.814 total time=   5.5s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.683 total time=   2.5s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.729 total time=   2.2s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.695 total time=   2.2s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.712 total time=   2.2s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.678 total time=   2.4s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.683 total time=   2.2s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.814 total time=   3.2s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.746 total time=   1.7s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.780 total time=   2.8s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.661 total time=   2.1s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.717 total time=  20.9s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.644 total time=  19.7s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.695 total time=  19.6s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.661 total time=  22.6s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.763 total time=  21.8s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.833 total time=   4.9s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.644 total time=   5.4s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.695 total time=   4.8s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.695 total time=   4.6s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.780 total time=   5.2s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.817 total time=   2.3s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.746 total time=   2.1s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.780 total time=   2.3s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.610 total time=   2.0s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.729 total time=   2.2s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.717 total time=   3.1s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.763 total time=   1.9s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.729 total time=   2.8s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.610 total time=   3.0s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.797 total time=   1.8s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.767 total time=  20.6s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.729 total time=  20.4s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.712 total time=  23.5s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.678 total time=  20.4s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.678 total time=  20.3s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.817 total time=   5.0s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.780 total time=   5.1s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.763 total time=   4.5s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.746 total time=   4.6s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.797 total time=   4.8s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.750 total time=   2.1s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.746 total time=   2.1s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.712 total time=   2.0s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.610 total time=   1.9s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.644 total time=   2.1s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.683 total time=   2.2s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.831 total time=   2.4s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.763 total time=   3.6s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.610 total time=   1.8s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.695 total time=   2.2s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.717 total time=  19.8s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.763 total time=  19.3s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.661 total time=  21.3s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.695 total time=  19.1s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.763 total time=  21.6s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.817 total time=   5.1s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.763 total time=   4.6s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.746 total time=   5.1s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.678 total time=   4.7s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.780 total time=   4.7s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.683 total time=   2.2s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.864 total time=   2.0s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.797 total time=   2.0s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.797 total time=   2.2s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.712 total time=   2.3s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.667 total time=   1.8s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.780 total time=   1.7s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.712 total time=   1.8s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.763 total time=   2.0s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.763 total time=   2.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337315e80&gt;),\n",
       "                                       (&#x27;mlpclassifier&#x27;, MLPClassifier())]),\n",
       "             param_grid={&#x27;mlpclassifier__alpha&#x27;: [1e-06, 1e-05, 0.0001, 0.001],\n",
       "                         &#x27;mlpclassifier__learning_rate&#x27;: [&#x27;adaptive&#x27;],\n",
       "                         &#x27;mlpclassifier__learning_rate_init&#x27;: [1e-05, 0.0001,\n",
       "                                                               0.001, 0.01],\n",
       "                         &#x27;mlpclassifier__max_iter&#x27;: [4000]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337315e80&gt;),\n",
       "                                       (&#x27;mlpclassifier&#x27;, MLPClassifier())]),\n",
       "             param_grid={&#x27;mlpclassifier__alpha&#x27;: [1e-06, 1e-05, 0.0001, 0.001],\n",
       "                         &#x27;mlpclassifier__learning_rate&#x27;: [&#x27;adaptive&#x27;],\n",
       "                         &#x27;mlpclassifier__learning_rate_init&#x27;: [1e-05, 0.0001,\n",
       "                                                               0.001, 0.01],\n",
       "                         &#x27;mlpclassifier__max_iter&#x27;: [4000]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                 &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337315e80&gt;),\n",
       "                (&#x27;mlpclassifier&#x27;, MLPClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FreezingOfGaitDatasetBuilder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337315e80&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=Pipeline(steps=[('freezingofgaitdatasetbuilder',\n",
       "                                        <__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337315e80>),\n",
       "                                       ('mlpclassifier', MLPClassifier())]),\n",
       "             param_grid={'mlpclassifier__alpha': [1e-06, 1e-05, 0.0001, 0.001],\n",
       "                         'mlpclassifier__learning_rate': ['adaptive'],\n",
       "                         'mlpclassifier__learning_rate_init': [1e-05, 0.0001,\n",
       "                                                               0.001, 0.01],\n",
       "                         'mlpclassifier__max_iter': [4000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP Classifier\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "mlp_classifier_true = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=True), MLPClassifier())\n",
    "\n",
    "mlp_cross_val_true = GridSearchCV(mlp_classifier_true, {\"mlpclassifier__alpha\": [0.000001, 0.00001, 0.0001, 0.001], \"mlpclassifier__learning_rate\": [\"adaptive\"], \"mlpclassifier__learning_rate_init\": [0.00001, 0.0001, 0.001, 0.01], \"mlpclassifier__max_iter\": [4000]}, verbose = 3, error_score=\"raise\")\n",
    "\n",
    "mlp_cross_val_true.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "bcb0da7d-749d-4044-ace3-714de9ba0d07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.767 total time=  23.5s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.763 total time=  22.1s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.712 total time=  23.1s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.780 total time=  20.9s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.763 total time=  22.6s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.833 total time=   5.3s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.746 total time=   4.8s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.746 total time=   5.4s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.797 total time=   4.7s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.847 total time=   4.8s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.800 total time=   2.6s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.780 total time=   2.7s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.797 total time=   2.7s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.780 total time=   2.5s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.797 total time=   3.3s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.900 total time=   2.7s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.814 total time=   3.1s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.780 total time=   3.3s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.746 total time=   1.9s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-06, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.814 total time=   1.9s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.767 total time=  22.0s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.814 total time=  21.2s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.780 total time=  20.9s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.712 total time=  20.3s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.814 total time=  21.4s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.767 total time=   5.3s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.695 total time=   4.3s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.780 total time=   6.1s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.797 total time=   5.5s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.814 total time=   4.9s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.817 total time=   3.0s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.797 total time=   2.3s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.831 total time=   3.0s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.814 total time=   2.7s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.797 total time=   3.8s\n",
      "[CV 1/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.783 total time=   2.0s\n",
      "[CV 2/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.847 total time=   2.8s\n",
      "[CV 3/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.814 total time=   2.7s\n",
      "[CV 4/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.712 total time=   4.0s\n",
      "[CV 5/5] END mlpclassifier__alpha=1e-05, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.814 total time=   2.3s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.750 total time=  26.3s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.746 total time=  27.5s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.763 total time=  23.2s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.712 total time=  23.5s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.814 total time=  22.6s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.817 total time=   4.7s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.763 total time=   5.1s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.797 total time=   5.0s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.797 total time=   5.8s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.864 total time=   5.2s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.867 total time=   2.4s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.780 total time=   2.5s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.864 total time=   3.4s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.814 total time=   2.7s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.864 total time=   2.8s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.700 total time=   2.1s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.780 total time=   2.1s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.881 total time=   3.5s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.814 total time=   3.5s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.0001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.763 total time=   2.3s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.850 total time=  23.4s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.864 total time=  18.9s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.814 total time=  20.7s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.780 total time=  22.5s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=1e-05, mlpclassifier__max_iter=4000;, score=0.814 total time=  24.0s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.817 total time=   5.3s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.746 total time=   4.9s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.780 total time=   5.3s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.729 total time=   5.1s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.0001, mlpclassifier__max_iter=4000;, score=0.915 total time=   5.2s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.833 total time=   2.3s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.847 total time=   2.3s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.780 total time=   2.7s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.814 total time=   2.5s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.001, mlpclassifier__max_iter=4000;, score=0.763 total time=   4.7s\n",
      "[CV 1/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.800 total time=   2.3s\n",
      "[CV 2/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.746 total time=   1.9s\n",
      "[CV 3/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.814 total time=   1.9s\n",
      "[CV 4/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.763 total time=   2.9s\n",
      "[CV 5/5] END mlpclassifier__alpha=0.001, mlpclassifier__learning_rate=adaptive, mlpclassifier__learning_rate_init=0.01, mlpclassifier__max_iter=4000;, score=0.881 total time=   2.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d2b790&gt;),\n",
       "                                       (&#x27;mlpclassifier&#x27;, MLPClassifier())]),\n",
       "             param_grid={&#x27;mlpclassifier__alpha&#x27;: [1e-06, 1e-05, 0.0001, 0.001],\n",
       "                         &#x27;mlpclassifier__learning_rate&#x27;: [&#x27;adaptive&#x27;],\n",
       "                         &#x27;mlpclassifier__learning_rate_init&#x27;: [1e-05, 0.0001,\n",
       "                                                               0.001, 0.01],\n",
       "                         &#x27;mlpclassifier__max_iter&#x27;: [4000]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d2b790&gt;),\n",
       "                                       (&#x27;mlpclassifier&#x27;, MLPClassifier())]),\n",
       "             param_grid={&#x27;mlpclassifier__alpha&#x27;: [1e-06, 1e-05, 0.0001, 0.001],\n",
       "                         &#x27;mlpclassifier__learning_rate&#x27;: [&#x27;adaptive&#x27;],\n",
       "                         &#x27;mlpclassifier__learning_rate_init&#x27;: [1e-05, 0.0001,\n",
       "                                                               0.001, 0.01],\n",
       "                         &#x27;mlpclassifier__max_iter&#x27;: [4000]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                 &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d2b790&gt;),\n",
       "                (&#x27;mlpclassifier&#x27;, MLPClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FreezingOfGaitDatasetBuilder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d2b790&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=Pipeline(steps=[('freezingofgaitdatasetbuilder',\n",
       "                                        <__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d2b790>),\n",
       "                                       ('mlpclassifier', MLPClassifier())]),\n",
       "             param_grid={'mlpclassifier__alpha': [1e-06, 1e-05, 0.0001, 0.001],\n",
       "                         'mlpclassifier__learning_rate': ['adaptive'],\n",
       "                         'mlpclassifier__learning_rate_init': [1e-05, 0.0001,\n",
       "                                                               0.001, 0.01],\n",
       "                         'mlpclassifier__max_iter': [4000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP Classifier\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "mlp_classifier_false = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), MLPClassifier())\n",
    "\n",
    "mlp_cross_val_false = GridSearchCV(mlp_classifier_false, {\"mlpclassifier__alpha\": [0.000001, 0.00001, 0.0001, 0.001], \"mlpclassifier__learning_rate\": [\"adaptive\"], \"mlpclassifier__learning_rate_init\": [0.00001, 0.0001, 0.001, 0.01], \"mlpclassifier__max_iter\": [4000]}, verbose = 3, error_score=\"raise\")\n",
    "\n",
    "mlp_cross_val_false.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cf8a9203-50d2-4cca-95c7-fa558dd36a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP Score with Preprocessing: 0.7837853107344632\n",
      "Best MLP Parameters with Preprocessing: {'mlpclassifier__alpha': 1e-06, 'mlpclassifier__learning_rate': 'adaptive', 'mlpclassifier__learning_rate_init': 0.0001, 'mlpclassifier__max_iter': 4000}\n",
      "Best MLP Score without Preprocessing: 0.8377401129943504\n",
      "Best MLP Parameters without Preprocessing: {'mlpclassifier__alpha': 0.0001, 'mlpclassifier__learning_rate': 'adaptive', 'mlpclassifier__learning_rate_init': 0.001, 'mlpclassifier__max_iter': 4000}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best MLP Score with Preprocessing:\", mlp_cross_val_true.best_score_)\n",
    "print(\"Best MLP Parameters with Preprocessing:\", mlp_cross_val_true.best_params_)\n",
    "print(\"Best MLP Score without Preprocessing:\", mlp_cross_val_false.best_score_)\n",
    "print(\"Best MLP Parameters without Preprocessing:\", mlp_cross_val_false.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "2bf5e433-8257-4193-b3e5-1b278fb2abcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy Score: 0.8116\n",
      "MLP Macro-Averaged F1 Score: 0.8102\n",
      "MLP Micro-Averaged F1 Score: 0.8116\n"
     ]
    }
   ],
   "source": [
    "final_mlp_classifier = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), MLPClassifier(alpha=0.0001, learning_rate=\"adaptive\", learning_rate_init=0.001, max_iter=4000, random_state=3))\n",
    "final_mlp_classifier.fit(train_data, y_train)\n",
    "y_pred = final_mlp_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_mlp = f1_score(y_test, y_pred, average=\"micro\")\n",
    "macro_f1_score_mlp = f1_score(y_test, y_pred, average=\"macro\")\n",
    "accuracy_score_mlp = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"MLP Accuracy Score:\", round(accuracy_score_mlp, 4))\n",
    "print(\"MLP Macro-Averaged F1 Score:\", round(macro_f1_score_mlp, 4))\n",
    "print(\"MLP Micro-Averaged F1 Score:\", round(micro_f1_score_mlp, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f0b4008b-04a1-4629-81c7-dfa02c98a602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.517 total time=   1.2s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.525 total time=   1.0s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.517 total time=   1.0s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.525 total time=   1.0s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.517 total time=   0.9s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.517 total time=   0.9s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.517 total time=   0.9s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.517 total time=   0.9s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=uniform;, score=0.517 total time=   0.9s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.9s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=distance;, score=0.517 total time=   0.9s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d044c0&gt;),\n",
       "                                       (&#x27;kneighborsclassifier&#x27;,\n",
       "                                        KNeighborsClassifier())]),\n",
       "             param_grid={&#x27;kneighborsclassifier__n_neighbors&#x27;: [3, 5, 7, 9],\n",
       "                         &#x27;kneighborsclassifier__weights&#x27;: [&#x27;uniform&#x27;,\n",
       "                                                           &#x27;distance&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d044c0&gt;),\n",
       "                                       (&#x27;kneighborsclassifier&#x27;,\n",
       "                                        KNeighborsClassifier())]),\n",
       "             param_grid={&#x27;kneighborsclassifier__n_neighbors&#x27;: [3, 5, 7, 9],\n",
       "                         &#x27;kneighborsclassifier__weights&#x27;: [&#x27;uniform&#x27;,\n",
       "                                                           &#x27;distance&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                 &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d044c0&gt;),\n",
       "                (&#x27;kneighborsclassifier&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FreezingOfGaitDatasetBuilder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d044c0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=Pipeline(steps=[('freezingofgaitdatasetbuilder',\n",
       "                                        <__main__.FreezingOfGaitDatasetBuilder object at 0x7ff337d044c0>),\n",
       "                                       ('kneighborsclassifier',\n",
       "                                        KNeighborsClassifier())]),\n",
       "             param_grid={'kneighborsclassifier__n_neighbors': [3, 5, 7, 9],\n",
       "                         'kneighborsclassifier__weights': ['uniform',\n",
       "                                                           'distance']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN Classifier\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "knn_classifier_true = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=True), KNeighborsClassifier())\n",
    "\n",
    "knn_cross_val_true = GridSearchCV(knn_classifier_true, {\"kneighborsclassifier__n_neighbors\": [3, 5, 7, 9], \"kneighborsclassifier__weights\": [\"uniform\", \"distance\"]}, verbose = 3, error_score=\"raise\")\n",
    "\n",
    "knn_cross_val_true.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "500b9dad-235b-4496-a84d-d3834460ebe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.517 total time=   0.8s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.517 total time=   0.8s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.517 total time=   1.2s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.517 total time=   0.8s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.517 total time=   0.8s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.517 total time=   0.8s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=uniform;, score=0.517 total time=   0.8s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=distance;, score=0.517 total time=   0.8s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=9, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=11, kneighborsclassifier__weights=uniform;, score=0.517 total time=   0.8s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=11, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=11, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=11, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=11, kneighborsclassifier__weights=uniform;, score=0.525 total time=   0.8s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=11, kneighborsclassifier__weights=distance;, score=0.517 total time=   0.8s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=11, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=11, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=11, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=11, kneighborsclassifier__weights=distance;, score=0.525 total time=   0.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff334f059d0&gt;),\n",
       "                                       (&#x27;kneighborsclassifier&#x27;,\n",
       "                                        KNeighborsClassifier())]),\n",
       "             param_grid={&#x27;kneighborsclassifier__n_neighbors&#x27;: [3, 5, 7, 9, 11],\n",
       "                         &#x27;kneighborsclassifier__weights&#x27;: [&#x27;uniform&#x27;,\n",
       "                                                           &#x27;distance&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff334f059d0&gt;),\n",
       "                                       (&#x27;kneighborsclassifier&#x27;,\n",
       "                                        KNeighborsClassifier())]),\n",
       "             param_grid={&#x27;kneighborsclassifier__n_neighbors&#x27;: [3, 5, 7, 9, 11],\n",
       "                         &#x27;kneighborsclassifier__weights&#x27;: [&#x27;uniform&#x27;,\n",
       "                                                           &#x27;distance&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                 &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff334f059d0&gt;),\n",
       "                (&#x27;kneighborsclassifier&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FreezingOfGaitDatasetBuilder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff334f059d0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=Pipeline(steps=[('freezingofgaitdatasetbuilder',\n",
       "                                        <__main__.FreezingOfGaitDatasetBuilder object at 0x7ff334f059d0>),\n",
       "                                       ('kneighborsclassifier',\n",
       "                                        KNeighborsClassifier())]),\n",
       "             param_grid={'kneighborsclassifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "                         'kneighborsclassifier__weights': ['uniform',\n",
       "                                                           'distance']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN Classifier\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "knn_classifier_false = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), KNeighborsClassifier())\n",
    "\n",
    "knn_cross_val_false = GridSearchCV(knn_classifier_false, {\"kneighborsclassifier__n_neighbors\": [3, 5, 7, 9, 11], \"kneighborsclassifier__weights\": [\"uniform\", \"distance\"]}, verbose = 3, error_score=\"raise\")\n",
    "\n",
    "knn_cross_val_false.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "79bbdb2c-b3fb-432d-8dd0-79bb48effe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN Score with Preprocessing: 0.5236723163841808\n",
      "Best KNN Parameters with Preprocessing: {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Best KNN Score without Preprocessing: 0.5236723163841808\n",
      "Best KNN Parameters without Preprocessing: {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best KNN Score with Preprocessing:\", knn_cross_val_true.best_score_)\n",
    "print(\"Best KNN Parameters with Preprocessing:\", knn_cross_val_true.best_params_)\n",
    "print(\"Best KNN Score without Preprocessing:\", knn_cross_val_false.best_score_)\n",
    "print(\"Best KNN Parameters without Preprocessing:\", knn_cross_val_false.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "408a214c-7f30-467e-b801-c4a75623a736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score: 0.5072\n",
      "KNN Macro-Averaged F1 Score: 0.3365\n",
      "KNN Micro-Averaged F1 Score: 0.5072\n"
     ]
    }
   ],
   "source": [
    "final_knn_classifier = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), KNeighborsClassifier(n_neighbors=3, weights='uniform'))\n",
    "final_knn_classifier.fit(train_data, y_train)\n",
    "y_pred = final_knn_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_knn = f1_score(y_test, y_pred, average=\"micro\")\n",
    "macro_f1_score_knn = f1_score(y_test, y_pred, average=\"macro\")\n",
    "accuracy_score_knn = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"KNN Accuracy Score:\", round(accuracy_score_knn, 4))\n",
    "print(\"KNN Macro-Averaged F1 Score:\", round(macro_f1_score_knn, 4))\n",
    "print(\"KNN Micro-Averaged F1 Score:\", round(micro_f1_score_knn, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ca45efa9-e43d-49a3-8fe1-f9a3b85b22e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.700 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.627 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.678 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.695 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.746 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.700 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.610 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.678 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.746 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.678 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.733 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.678 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.678 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.763 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.678 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.733 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.661 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.661 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.763 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.678 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.733 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.661 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.695 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.712 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.559 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.717 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.644 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.661 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.763 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.576 total time=   1.4s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.750 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.695 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.661 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.729 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.627 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.750 total time=   1.2s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.627 total time=   1.2s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.644 total time=   1.2s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.729 total time=   1.2s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.746 total time=   1.2s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.717 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.695 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.678 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.729 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.661 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.750 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.712 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.678 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.797 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.644 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.733 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.644 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.695 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.780 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.729 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.733 total time=   1.2s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.695 total time=   1.2s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.644 total time=   1.2s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.797 total time=   1.2s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.644 total time=   1.2s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.717 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.763 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.678 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.678 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.763 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.717 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.661 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.695 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.729 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.678 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.717 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.695 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.661 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.729 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.661 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.717 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.678 total time=   1.2s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.695 total time=   1.2s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.763 total time=   1.2s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.661 total time=   1.2s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.767 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.661 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.729 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.746 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.661 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.683 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.661 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.678 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.780 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.644 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.733 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.644 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.712 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.763 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.695 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.700 total time=   1.2s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.746 total time=   1.2s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.678 total time=   1.2s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.746 total time=   1.2s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.678 total time=   1.2s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.717 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.627 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.661 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.797 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.746 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.733 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.661 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.695 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.729 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.729 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.683 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.695 total time=   1.2s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.678 total time=   1.2s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.780 total time=   1.2s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.712 total time=   1.2s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.700 total time=   1.2s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.695 total time=   1.2s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.661 total time=   1.2s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.780 total time=   1.2s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.678 total time=   1.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff352e8ca60&gt;),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={&#x27;randomforestclassifier__criterion&#x27;: [&#x27;gini&#x27;,\n",
       "                                                               &#x27;entropy&#x27;],\n",
       "                         &#x27;randomforestclassifier__max_depth&#x27;: [4, 7, 10],\n",
       "                         &#x27;randomforestclassifier__max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                         &#x27;randomforestclassifier__n_estimators&#x27;: [50, 100, 150,\n",
       "                                                                  200]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff352e8ca60&gt;),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={&#x27;randomforestclassifier__criterion&#x27;: [&#x27;gini&#x27;,\n",
       "                                                               &#x27;entropy&#x27;],\n",
       "                         &#x27;randomforestclassifier__max_depth&#x27;: [4, 7, 10],\n",
       "                         &#x27;randomforestclassifier__max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                         &#x27;randomforestclassifier__n_estimators&#x27;: [50, 100, 150,\n",
       "                                                                  200]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-86\" type=\"checkbox\" ><label for=\"sk-estimator-id-86\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                 &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff352e8ca60&gt;),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-87\" type=\"checkbox\" ><label for=\"sk-estimator-id-87\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FreezingOfGaitDatasetBuilder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff352e8ca60&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=Pipeline(steps=[('freezingofgaitdatasetbuilder',\n",
       "                                        <__main__.FreezingOfGaitDatasetBuilder object at 0x7ff352e8ca60>),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={'randomforestclassifier__criterion': ['gini',\n",
       "                                                               'entropy'],\n",
       "                         'randomforestclassifier__max_depth': [4, 7, 10],\n",
       "                         'randomforestclassifier__max_features': ['sqrt'],\n",
       "                         'randomforestclassifier__n_estimators': [50, 100, 150,\n",
       "                                                                  200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "rf_classifier_true = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=True), RandomForestClassifier())\n",
    "\n",
    "rf_cross_val_true = GridSearchCV(rf_classifier_true, { \n",
    "    'randomforestclassifier__n_estimators': [50, 100, 150, 200],\n",
    "    'randomforestclassifier__max_features': ['sqrt'],\n",
    "    'randomforestclassifier__max_depth' : [4, 7, 10],\n",
    "    'randomforestclassifier__criterion' :['gini', 'entropy']\n",
    "}, verbose = 3, error_score=\"raise\")\n",
    "\n",
    "rf_cross_val_true.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c125b772-45d7-49b4-8a94-8c562ece5f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.733 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.746 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.814 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.678 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.746 total time=   1.3s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.700 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.746 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.831 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.712 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.797 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.667 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.729 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.831 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.746 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.780 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.717 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.729 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.831 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.712 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.746 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.717 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.746 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.780 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.814 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.814 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.633 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.780 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.847 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.729 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.797 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.667 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.729 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.831 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.729 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.797 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.683 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.712 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.814 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.729 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.831 total time=   1.2s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.617 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.763 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.831 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.780 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.763 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.667 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.746 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.847 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.780 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.831 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.717 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.746 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.814 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.746 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.780 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.683 total time=   1.2s\n",
      "[CV 2/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.729 total time=   1.2s\n",
      "[CV 3/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.864 total time=   1.2s\n",
      "[CV 4/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.712 total time=   1.2s\n",
      "[CV 5/5] END randomforestclassifier__criterion=gini, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.797 total time=   1.2s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.733 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.763 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.780 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.712 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.763 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.733 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.746 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.797 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.729 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.763 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.683 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.729 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.847 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.695 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.797 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.700 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.712 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.847 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.729 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=4, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.814 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.700 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.729 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.831 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.746 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.797 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.700 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.678 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.814 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.712 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.831 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.700 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.797 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.847 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.780 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.814 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.767 total time=   1.2s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.729 total time=   1.2s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.831 total time=   1.2s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.780 total time=   1.2s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=7, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.797 total time=   1.2s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.683 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.695 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.814 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.729 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=50;, score=0.729 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.750 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.729 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.847 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.763 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=100;, score=0.763 total time=   1.0s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.700 total time=   1.5s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.712 total time=   1.1s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.831 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.763 total time=   1.1s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=150;, score=0.780 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.750 total time=   1.2s\n",
      "[CV 2/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.712 total time=   1.2s\n",
      "[CV 3/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.831 total time=   1.2s\n",
      "[CV 4/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.780 total time=   1.2s\n",
      "[CV 5/5] END randomforestclassifier__criterion=entropy, randomforestclassifier__max_depth=10, randomforestclassifier__max_features=sqrt, randomforestclassifier__n_estimators=200;, score=0.780 total time=   1.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb442c40&gt;),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={&#x27;randomforestclassifier__criterion&#x27;: [&#x27;gini&#x27;,\n",
       "                                                               &#x27;entropy&#x27;],\n",
       "                         &#x27;randomforestclassifier__max_depth&#x27;: [4, 7, 10],\n",
       "                         &#x27;randomforestclassifier__max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                         &#x27;randomforestclassifier__n_estimators&#x27;: [50, 100, 150,\n",
       "                                                                  200]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" ><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb442c40&gt;),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={&#x27;randomforestclassifier__criterion&#x27;: [&#x27;gini&#x27;,\n",
       "                                                               &#x27;entropy&#x27;],\n",
       "                         &#x27;randomforestclassifier__max_depth&#x27;: [4, 7, 10],\n",
       "                         &#x27;randomforestclassifier__max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                         &#x27;randomforestclassifier__n_estimators&#x27;: [50, 100, 150,\n",
       "                                                                  200]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                 &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb442c40&gt;),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-91\" type=\"checkbox\" ><label for=\"sk-estimator-id-91\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FreezingOfGaitDatasetBuilder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb442c40&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-92\" type=\"checkbox\" ><label for=\"sk-estimator-id-92\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=Pipeline(steps=[('freezingofgaitdatasetbuilder',\n",
       "                                        <__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb442c40>),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={'randomforestclassifier__criterion': ['gini',\n",
       "                                                               'entropy'],\n",
       "                         'randomforestclassifier__max_depth': [4, 7, 10],\n",
       "                         'randomforestclassifier__max_features': ['sqrt'],\n",
       "                         'randomforestclassifier__n_estimators': [50, 100, 150,\n",
       "                                                                  200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "rf_classifier_false = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), RandomForestClassifier())\n",
    "\n",
    "rf_cross_val_false = GridSearchCV(rf_classifier_false, { \n",
    "    'randomforestclassifier__n_estimators': [50, 100, 150, 200],\n",
    "    'randomforestclassifier__max_features': ['sqrt'],\n",
    "    'randomforestclassifier__max_depth' : [4, 7, 10],\n",
    "    'randomforestclassifier__criterion' :['gini', 'entropy']\n",
    "}, verbose = 3, error_score=\"raise\")\n",
    "\n",
    "rf_cross_val_false.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "dd5ac611-0b47-43e7-88a1-bfdb28a9dd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Score with Preprocessing: 0.7196045197740112\n",
      "Best Random Forest Parameters with Preprocessing: {'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 4, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__n_estimators': 50}\n",
      "Best Random Forest Score without Preprocessing: 0.7874576271186441\n",
      "Best Random Forest Parameters without Preprocessing: {'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Random Forest Score with Preprocessing:\", rf_cross_val_true.best_score_)\n",
    "print(\"Best Random Forest Parameters with Preprocessing:\", rf_cross_val_true.best_params_)\n",
    "print(\"Best Random Forest Score without Preprocessing:\", rf_cross_val_false.best_score_)\n",
    "print(\"Best Random Forest Parameters without Preprocessing:\", rf_cross_val_false.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e7344025-e7e0-4d6d-b9d6-e46386950b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score: 0.6667\n",
      "Random Forest Macro-Averaged F1 Score: 0.6621\n",
      "Random Forest Micro-Averaged F1 Score: 0.6667\n"
     ]
    }
   ],
   "source": [
    "final_rf_classifier = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=True), RandomForestClassifier(criterion='entropy', max_depth=7, max_features='sqrt', n_estimators=150))\n",
    "final_rf_classifier.fit(train_data, y_train)\n",
    "y_pred = final_rf_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_rf = f1_score(y_test, y_pred, average=\"micro\")\n",
    "macro_f1_score_rf = f1_score(y_test, y_pred, average=\"macro\")\n",
    "accuracy_score_rf = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest Accuracy Score:\", round(accuracy_score_rf, 4))\n",
    "print(\"Random Forest Macro-Averaged F1 Score:\", round(macro_f1_score_rf, 4))\n",
    "print(\"Random Forest Micro-Averaged F1 Score:\", round(micro_f1_score_rf, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "132b0d60-6577-40eb-acf1-3db3caf7f8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.517 total time=   1.1s\n",
      "[CV 2/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.475 total time=   1.4s\n",
      "[CV 3/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   1.3s\n",
      "[CV 4/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   1.4s\n",
      "[CV 5/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   1.3s\n",
      "[CV 1/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.800 total time=   3.3s\n",
      "[CV 2/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.763 total time=   2.5s\n",
      "[CV 3/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.814 total time=   3.6s\n",
      "[CV 4/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.797 total time=   3.3s\n",
      "[CV 5/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.864 total time=   3.5s\n",
      "[CV 1/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.517 total time=   1.0s\n",
      "[CV 2/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   1.0s\n",
      "[CV 3/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   1.0s\n",
      "[CV 4/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   1.0s\n",
      "[CV 5/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   1.2s\n",
      "[CV 1/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.800 total time=  10.1s\n",
      "[CV 2/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.780 total time=   7.6s\n",
      "[CV 3/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.797 total time=   7.9s\n",
      "[CV 4/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.780 total time=   8.0s\n",
      "[CV 5/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.864 total time=   8.6s\n",
      "[CV 1/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.717 total time= 1.4min\n",
      "[CV 2/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.712 total time= 1.3min\n",
      "[CV 3/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.712 total time= 1.3min\n",
      "[CV 4/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.712 total time=  56.3s\n",
      "[CV 5/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.814 total time= 1.0min\n",
      "[CV 1/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.800 total time=  17.7s\n",
      "[CV 2/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.780 total time=  16.3s\n",
      "[CV 3/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.797 total time=  17.1s\n",
      "[CV 4/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.780 total time=  15.3s\n",
      "[CV 5/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.864 total time=  18.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb135e20&gt;),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1],\n",
       "                         &#x27;logisticregression__max_iter&#x27;: [5000],\n",
       "                         &#x27;logisticregression__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;logisticregression__solver&#x27;: [&#x27;saga&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-93\" type=\"checkbox\" ><label for=\"sk-estimator-id-93\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb135e20&gt;),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1],\n",
       "                         &#x27;logisticregression__max_iter&#x27;: [5000],\n",
       "                         &#x27;logisticregression__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;logisticregression__solver&#x27;: [&#x27;saga&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-94\" type=\"checkbox\" ><label for=\"sk-estimator-id-94\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                 &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb135e20&gt;),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-95\" type=\"checkbox\" ><label for=\"sk-estimator-id-95\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FreezingOfGaitDatasetBuilder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb135e20&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-96\" type=\"checkbox\" ><label for=\"sk-estimator-id-96\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=Pipeline(steps=[('freezingofgaitdatasetbuilder',\n",
       "                                        <__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb135e20>),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression())]),\n",
       "             param_grid={'logisticregression__C': [0.001, 0.01, 0.1],\n",
       "                         'logisticregression__max_iter': [5000],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['saga']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "lr_classifier_true = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=True), LogisticRegression())\n",
    "\n",
    "lr_cross_val_true = GridSearchCV(lr_classifier_true, { \n",
    "    \"logisticregression__C\": [0.001, 0.01, 0.1], \"logisticregression__penalty\": [\"l1\", \"l2\"], \"logisticregression__solver\": [\"saga\"], \"logisticregression__max_iter\": [5000]\n",
    "}, verbose = 3, error_score=\"raise\")\n",
    "\n",
    "lr_cross_val_true.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "df108fea-19c4-4ffd-bd62-652c07170eb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.517 total time=   0.8s\n",
      "[CV 2/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   0.9s\n",
      "[CV 3/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   0.9s\n",
      "[CV 4/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   0.8s\n",
      "[CV 5/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   0.9s\n",
      "[CV 1/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.833 total time=   4.4s\n",
      "[CV 2/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.780 total time=   3.5s\n",
      "[CV 3/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.814 total time=   4.4s\n",
      "[CV 4/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.780 total time=   4.0s\n",
      "[CV 5/5] END logisticregression__C=0.001, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.881 total time=   4.7s\n",
      "[CV 1/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.517 total time=   1.0s\n",
      "[CV 2/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   1.0s\n",
      "[CV 3/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   1.0s\n",
      "[CV 4/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   1.0s\n",
      "[CV 5/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.525 total time=   1.0s\n",
      "[CV 1/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.833 total time=  11.8s\n",
      "[CV 2/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.780 total time=   9.9s\n",
      "[CV 3/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.831 total time=  11.6s\n",
      "[CV 4/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.797 total time=  10.5s\n",
      "[CV 5/5] END logisticregression__C=0.01, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.898 total time=  12.7s\n",
      "[CV 1/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.767 total time= 1.6min\n",
      "[CV 2/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.797 total time= 1.8min\n",
      "[CV 3/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.814 total time= 1.6min\n",
      "[CV 4/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.797 total time= 2.5min\n",
      "[CV 5/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.814 total time= 1.9min\n",
      "[CV 1/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.833 total time=  29.9s\n",
      "[CV 2/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.780 total time=  25.3s\n",
      "[CV 3/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.831 total time=  27.6s\n",
      "[CV 4/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.797 total time=  28.0s\n",
      "[CV 5/5] END logisticregression__C=0.1, logisticregression__max_iter=5000, logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.898 total time=  31.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb13c2e0&gt;),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1],\n",
       "                         &#x27;logisticregression__max_iter&#x27;: [5000],\n",
       "                         &#x27;logisticregression__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;logisticregression__solver&#x27;: [&#x27;saga&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-97\" type=\"checkbox\" ><label for=\"sk-estimator-id-97\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                                        &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb13c2e0&gt;),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1],\n",
       "                         &#x27;logisticregression__max_iter&#x27;: [5000],\n",
       "                         &#x27;logisticregression__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;logisticregression__solver&#x27;: [&#x27;saga&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-98\" type=\"checkbox\" ><label for=\"sk-estimator-id-98\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;freezingofgaitdatasetbuilder&#x27;,\n",
       "                 &lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb13c2e0&gt;),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-99\" type=\"checkbox\" ><label for=\"sk-estimator-id-99\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FreezingOfGaitDatasetBuilder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb13c2e0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-100\" type=\"checkbox\" ><label for=\"sk-estimator-id-100\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=Pipeline(steps=[('freezingofgaitdatasetbuilder',\n",
       "                                        <__main__.FreezingOfGaitDatasetBuilder object at 0x7ff2eb13c2e0>),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression())]),\n",
       "             param_grid={'logisticregression__C': [0.001, 0.01, 0.1],\n",
       "                         'logisticregression__max_iter': [5000],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['saga']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "lr_classifier_false = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), LogisticRegression())\n",
    "\n",
    "lr_cross_val_false = GridSearchCV(lr_classifier_false, { \n",
    "    \"logisticregression__C\": [0.001, 0.01, 0.1], \"logisticregression__penalty\": [\"l1\", \"l2\"], \"logisticregression__solver\": [\"saga\"], \"logisticregression__max_iter\": [5000]\n",
    "}, verbose = 3, error_score=\"raise\")\n",
    "\n",
    "lr_cross_val_false.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4e9c28bb-5be4-4d00-858c-6c846c01f771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Score with Preprocessing: 0.8074576271186441\n",
      "Best Logistic Regression Parameters with Preprocessing: {'logisticregression__C': 0.001, 'logisticregression__max_iter': 5000, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'saga'}\n",
      "Best Logistic Regression Score without Preprocessing: 0.827683615819209\n",
      "Best Logistic Regression Parameters without Preprocessing: {'logisticregression__C': 0.01, 'logisticregression__max_iter': 5000, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Logistic Regression Score with Preprocessing:\", lr_cross_val_true.best_score_)\n",
    "print(\"Best Logistic Regression Parameters with Preprocessing:\", lr_cross_val_true.best_params_)\n",
    "print(\"Best Logistic Regression Score without Preprocessing:\", lr_cross_val_false.best_score_)\n",
    "print(\"Best Logistic Regression Parameters without Preprocessing:\", lr_cross_val_false.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "3641ce12-7fc8-46f3-a622-d9d47b6e242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score: 0.8261\n",
      "Logistic Regression Macro-Averaged F1 Score: 0.8231\n",
      "Logistic Regression Micro-Averaged F1 Score: 0.8261\n"
     ]
    }
   ],
   "source": [
    "final_lr_classifier = make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), LogisticRegression(C=0.01, max_iter=5000, penalty='l2', solver='saga', random_state=3))\n",
    "final_lr_classifier.fit(train_data, y_train)\n",
    "y_pred = final_lr_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_lr = f1_score(y_test, y_pred, average=\"micro\")\n",
    "macro_f1_score_lr = f1_score(y_test, y_pred, average=\"macro\")\n",
    "accuracy_score_lr = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Logistic Regression Accuracy Score:\", round(accuracy_score_lr, 4))\n",
    "print(\"Logistic Regression Macro-Averaged F1 Score:\", round(macro_f1_score_lr, 4))\n",
    "print(\"Logistic Regression Micro-Averaged F1 Score:\", round(micro_f1_score_lr, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "cc17b595-5149-4ce2-a896-550cf7a7a066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy Score: 0.8551\n",
      "Ensemble Macro-Averaged F1 Score: 0.8543\n",
      "Ensemble Micro-Averaged F1 Score: 0.8551\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Classifier (from above classifiers)\n",
    "# Using a pipeline to avoid train/test leakage with vectorization\n",
    "ensemble_classifier = VotingClassifier(estimators=[\n",
    "    (\"nb\", make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), GaussianNB())),\n",
    "    (\"mlp\", make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), MLPClassifier(alpha=0.0001, learning_rate=\"adaptive\", learning_rate_init=0.001, max_iter=4000, random_state=3))),\n",
    "    (\"knn\", make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), KNeighborsClassifier(n_neighbors=3, weights='uniform'))),\n",
    "    (\"svc\", make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), SVC(C=10, kernel=\"sigmoid\", probability=True, random_state=3))),\n",
    "    (\"rf\", make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), RandomForestClassifier(criterion='entropy', max_depth=7, max_features='sqrt', n_estimators=150, random_state=3))),\n",
    "    (\"lr\", make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), LogisticRegression(C=0.01, max_iter=5000, penalty='l2', solver='saga', random_state=3)))\n",
    "    ], voting='soft')\n",
    "\n",
    "ensemble_classifier.fit(train_data, y_train)\n",
    "\n",
    "y_pred = ensemble_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_ensemble = f1_score(y_test, y_pred, average=\"micro\")\n",
    "macro_f1_score_ensemble = f1_score(y_test, y_pred, average=\"macro\")\n",
    "accuracy_score_ensemble = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Ensemble Accuracy Score:\", round(accuracy_score_ensemble, 4))\n",
    "print(\"Ensemble Macro-Averaged F1 Score:\", round(macro_f1_score_ensemble, 4))\n",
    "print(\"Ensemble Micro-Averaged F1 Score:\", round(micro_f1_score_ensemble, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "6610c5b0-92d6-4077-a604-0db9068378ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4\n",
      "Training set size: 5\n",
      "Training set size: 6\n",
      "Training set size: 7\n",
      "Training set size: 8\n",
      "Training set size: 9\n",
      "Training set size: 10\n",
      "Training set size: 11\n",
      "Training set size: 12\n",
      "Training set size: 13\n",
      "Training set size: 14\n",
      "Training set size: 15\n",
      "Training set size: 16\n",
      "Training set size: 17\n",
      "Training set size: 18\n",
      "Training set size: 19\n",
      "Training set size: 20\n",
      "Training set size: 21\n",
      "Training set size: 22\n",
      "Training set size: 23\n",
      "Training set size: 24\n",
      "Training set size: 25\n",
      "Training set size: 26\n",
      "Training set size: 27\n",
      "Training set size: 28\n",
      "Training set size: 29\n",
      "Training set size: 30\n",
      "Training set size: 31\n",
      "Training set size: 32\n",
      "Training set size: 33\n",
      "Training set size: 34\n",
      "Training set size: 35\n",
      "Training set size: 36\n",
      "Training set size: 37\n",
      "Training set size: 38\n",
      "Training set size: 39\n",
      "Training set size: 40\n",
      "Training set size: 41\n",
      "Training set size: 42\n",
      "Training set size: 43\n",
      "Training set size: 44\n",
      "Training set size: 45\n",
      "Training set size: 46\n",
      "Training set size: 47\n",
      "Training set size: 48\n",
      "Training set size: 49\n",
      "Training set size: 50\n",
      "Training set size: 51\n",
      "Training set size: 52\n",
      "Training set size: 53\n",
      "Training set size: 54\n",
      "Training set size: 55\n",
      "Training set size: 56\n",
      "Training set size: 57\n",
      "Training set size: 58\n",
      "Training set size: 59\n",
      "Training set size: 60\n",
      "Training set size: 61\n",
      "Training set size: 62\n",
      "Training set size: 63\n",
      "Training set size: 64\n",
      "Training set size: 65\n",
      "Training set size: 66\n",
      "Training set size: 67\n",
      "Training set size: 68\n",
      "Training set size: 69\n",
      "Training set size: 70\n",
      "Training set size: 71\n",
      "Training set size: 72\n",
      "Training set size: 73\n",
      "Training set size: 74\n",
      "Training set size: 75\n",
      "Training set size: 76\n",
      "Training set size: 77\n",
      "Training set size: 78\n",
      "Training set size: 79\n",
      "Training set size: 80\n",
      "Training set size: 81\n",
      "Training set size: 82\n",
      "Training set size: 83\n",
      "Training set size: 84\n",
      "Training set size: 85\n",
      "Training set size: 86\n",
      "Training set size: 87\n",
      "Training set size: 88\n",
      "Training set size: 89\n",
      "Training set size: 90\n",
      "Training set size: 91\n",
      "Training set size: 92\n",
      "Training set size: 93\n",
      "Training set size: 94\n",
      "Training set size: 95\n",
      "Training set size: 96\n",
      "Training set size: 97\n",
      "Training set size: 98\n",
      "Training set size: 99\n",
      "Training set size: 100\n",
      "Training set size: 101\n",
      "Training set size: 102\n",
      "Training set size: 103\n",
      "Training set size: 104\n",
      "Training set size: 105\n",
      "Training set size: 106\n",
      "Training set size: 107\n",
      "Training set size: 108\n",
      "Training set size: 109\n",
      "Training set size: 110\n",
      "Training set size: 111\n",
      "Training set size: 112\n",
      "Training set size: 113\n",
      "Training set size: 114\n",
      "Training set size: 115\n",
      "Training set size: 116\n",
      "Training set size: 117\n",
      "Training set size: 118\n",
      "Training set size: 119\n",
      "Training set size: 120\n",
      "Training set size: 121\n",
      "Training set size: 122\n",
      "Training set size: 123\n",
      "Training set size: 124\n",
      "Training set size: 125\n",
      "Training set size: 126\n",
      "Training set size: 127\n",
      "Training set size: 128\n",
      "Training set size: 129\n",
      "Training set size: 130\n",
      "Training set size: 131\n",
      "Training set size: 132\n",
      "Training set size: 133\n",
      "Training set size: 134\n",
      "Training set size: 135\n",
      "Training set size: 136\n",
      "Training set size: 137\n",
      "Training set size: 138\n",
      "Training set size: 139\n",
      "Training set size: 140\n",
      "Training set size: 141\n",
      "Training set size: 142\n",
      "Training set size: 143\n",
      "Training set size: 144\n",
      "Training set size: 145\n",
      "Training set size: 146\n",
      "Training set size: 147\n",
      "Training set size: 148\n",
      "Training set size: 149\n",
      "Training set size: 150\n",
      "Training set size: 151\n",
      "Training set size: 152\n",
      "Training set size: 153\n",
      "Training set size: 154\n",
      "Training set size: 155\n",
      "Training set size: 156\n",
      "Training set size: 157\n",
      "Training set size: 158\n",
      "Training set size: 159\n",
      "Training set size: 160\n",
      "Training set size: 161\n",
      "Training set size: 162\n",
      "Training set size: 163\n",
      "Training set size: 164\n",
      "Training set size: 165\n",
      "Training set size: 166\n",
      "Training set size: 167\n",
      "Training set size: 168\n",
      "Training set size: 169\n",
      "Training set size: 170\n",
      "Training set size: 171\n",
      "Training set size: 172\n",
      "Training set size: 173\n",
      "Training set size: 174\n",
      "Training set size: 175\n",
      "Training set size: 176\n",
      "Training set size: 177\n",
      "Training set size: 178\n",
      "Training set size: 179\n",
      "Training set size: 180\n",
      "Training set size: 181\n",
      "Training set size: 182\n",
      "Training set size: 183\n",
      "Training set size: 184\n",
      "Training set size: 185\n",
      "Training set size: 186\n",
      "Training set size: 187\n",
      "Training set size: 188\n",
      "Training set size: 189\n",
      "Training set size: 190\n",
      "Training set size: 191\n",
      "Training set size: 192\n",
      "Training set size: 193\n",
      "Training set size: 194\n",
      "Training set size: 195\n",
      "Training set size: 196\n",
      "Training set size: 197\n",
      "Training set size: 198\n",
      "Training set size: 199\n",
      "Training set size: 200\n",
      "Training set size: 201\n",
      "Training set size: 202\n",
      "Training set size: 203\n",
      "Training set size: 204\n",
      "Training set size: 205\n",
      "Training set size: 206\n",
      "Training set size: 207\n",
      "Training set size: 208\n",
      "Training set size: 209\n",
      "Training set size: 210\n",
      "Training set size: 211\n",
      "Training set size: 212\n",
      "Training set size: 213\n",
      "Training set size: 214\n",
      "Training set size: 215\n",
      "Training set size: 216\n",
      "Training set size: 217\n",
      "Training set size: 218\n",
      "Training set size: 219\n",
      "Training set size: 220\n",
      "Training set size: 221\n",
      "Training set size: 222\n",
      "Training set size: 223\n",
      "Training set size: 224\n",
      "Training set size: 225\n",
      "Training set size: 226\n",
      "Training set size: 227\n",
      "Training set size: 228\n",
      "Training set size: 229\n",
      "Training set size: 230\n",
      "Training set size: 231\n",
      "Training set size: 232\n",
      "Training set size: 233\n",
      "Training set size: 234\n",
      "Training set size: 235\n",
      "Training set size: 236\n",
      "Training set size: 237\n",
      "Training set size: 238\n",
      "Training set size: 239\n",
      "Training set size: 240\n",
      "Training set size: 241\n",
      "Training set size: 242\n",
      "Training set size: 243\n",
      "Training set size: 244\n",
      "Training set size: 245\n",
      "Training set size: 246\n",
      "Training set size: 247\n",
      "Training set size: 248\n",
      "Training set size: 249\n",
      "Training set size: 250\n",
      "Training set size: 251\n",
      "Training set size: 252\n",
      "Training set size: 253\n",
      "Training set size: 254\n",
      "Training set size: 255\n",
      "Training set size: 256\n",
      "Training set size: 257\n",
      "Training set size: 258\n",
      "Training set size: 259\n",
      "Training set size: 260\n",
      "Training set size: 261\n",
      "Training set size: 262\n",
      "Training set size: 263\n",
      "Training set size: 264\n",
      "Training set size: 265\n",
      "Training set size: 266\n",
      "Training set size: 267\n",
      "Training set size: 268\n",
      "Training set size: 269\n",
      "Training set size: 270\n",
      "Training set size: 271\n",
      "Training set size: 272\n",
      "Training set size: 273\n",
      "Training set size: 274\n",
      "Training set size: 275\n",
      "Training set size: 276\n",
      "Training set size: 277\n",
      "Training set size: 278\n",
      "Training set size: 279\n",
      "Training set size: 280\n",
      "Training set size: 281\n",
      "Training set size: 282\n",
      "Training set size: 283\n",
      "Training set size: 284\n",
      "Training set size: 285\n",
      "Training set size: 286\n",
      "Training set size: 287\n",
      "Training set size: 288\n",
      "Training set size: 289\n",
      "Training set size: 290\n",
      "Training set size: 291\n",
      "Training set size: 292\n",
      "Training set size: 293\n",
      "Training set size: 294\n",
      "Training set size: 295\n",
      "Training set size: 296\n"
     ]
    }
   ],
   "source": [
    "training_set_size_list = []\n",
    "performance_list = [] # Using micro-F1 score\n",
    "\n",
    "total_train_size = train_data.shape[0]\n",
    "for i in range(4, train_data.shape[0] + 1):\n",
    "\n",
    "    ensemble_classifier = VotingClassifier(estimators=[\n",
    "    (\"nb\", make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), GaussianNB())),\n",
    "    (\"mlp\", make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), MLPClassifier(alpha=0.0001, learning_rate=\"adaptive\", learning_rate_init=0.001, max_iter=4000, random_state=3))),\n",
    "    (\"knn\", make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), KNeighborsClassifier(n_neighbors=3, weights='uniform'))),\n",
    "    (\"svc\", make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), SVC(C=10, kernel=\"sigmoid\", probability=True, random_state=3))),\n",
    "    (\"rf\", make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), RandomForestClassifier(criterion='entropy', max_depth=7, max_features='sqrt', n_estimators=150, random_state=3))),\n",
    "    (\"lr\", make_pipeline(FreezingOfGaitDatasetBuilder(preprocess=False), LogisticRegression(C=0.01, max_iter=5000, penalty='l2', solver='saga', random_state=3)))\n",
    "    ], voting='soft')\n",
    "    \n",
    "    print(\"Training set size:\", i)\n",
    "    subsetted_train_data = train_data.iloc[0:i].copy()\n",
    "    subsetted_train_labels = y_train[0:i]\n",
    "    training_set_size_list.append(i)\n",
    "\n",
    "    ensemble_classifier.fit(subsetted_train_data, subsetted_train_labels)\n",
    "\n",
    "    y_pred = ensemble_classifier.predict(test_data)\n",
    "\n",
    "    micro_f1_score_ensemble = f1_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "    performance_list.append(micro_f1_score_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "32fb9b66-86da-4632-ac13-e53115d6c076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "ax.plot(training_set_size_list, performance_list)\n",
    "plt.xlabel(\"Training Set Size\")\n",
    "plt.ylabel(\"Micro-Averaged F1 Score\")\n",
    "plt.title(\"Training Set Size / Performance Curve\")\n",
    "plt.axhline(y = 0.825, xmin=0, xmax=1, color = \"red\", ls=\"--\")\n",
    "plt.show()\n",
    "fig.savefig(\"trainingset_performance_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "8b40b255-c083-4363-8e70-77ac2af4d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a custom \"classifier\" to handle data transformation... this is required so there is no train/test leakage through vectorized text\n",
    "# This will be put through a scikit-learn pipeline, which allows it to be used correctly with a hyperparameter search and cross validation\n",
    "class FreezingOfGaitDatasetBuilder_No_TFIDF():\n",
    "    def __init__(self, preprocess=True):\n",
    "        # self.tf_idf_vectorizer = None\n",
    "        self.ngram_vectorizer = None\n",
    "        self.word2vec_model = None\n",
    "        self.preprocess = preprocess\n",
    "    \n",
    "    def transform(self, input_df, **transform_params):\n",
    "        word_embeddings = None\n",
    "        # new_tfidf_data = None\n",
    "        new_ngram_data = None\n",
    "        \n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "        \n",
    "            # Word2Vec data\n",
    "            word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df_new])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            # new_tfidf_data = self.tf_idf_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            new_ngram_data = self.ngram_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "\n",
    "        else:\n",
    "            # Word2Vec data\n",
    "            word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df[\"fall_description\"]])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            # new_tfidf_data = self.tf_idf_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            new_ngram_data = self.ngram_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "\n",
    "        # Number of characters data\n",
    "        input_df['num_characters'] = input_df.apply(lambda row : len(row[\"fall_description\"]), axis = 1)\n",
    "        num_chars = input_df['num_characters'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # Average length of words data\n",
    "        input_df['avg_word_length'] = input_df.apply(lambda row: np.mean([len(word) for word in row[\"fall_description\"].split()]), axis=1)\n",
    "        avg_length = input_df['avg_word_length'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # Parts of speech data\n",
    "        pos_tag_counts = input_df.apply(lambda row: self.pos_tagger_func(row), axis = 1)\n",
    "        pos_tag_array = pos_tag_counts[[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"]].to_numpy()\n",
    "    \n",
    "        pre_finalized_data = np.hstack((word_embeddings, new_ngram_data, num_chars, avg_length, pos_tag_array))\n",
    "        standard_scaler = StandardScaler()\n",
    "        finalized_data = standard_scaler.fit_transform(pre_finalized_data)\n",
    "        return finalized_data\n",
    "    \n",
    "    def fit(self, input_df, y=None, **fit_params):\n",
    "        sentences = None\n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "            sentences = [sentence.split() for sentence in input_df_new]\n",
    "            self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            # self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            # self.tf_idf_vectorizer.fit(input_df_new.to_numpy())\n",
    "            self.ngram_vectorizer.fit(input_df_new.to_numpy())\n",
    "        else:\n",
    "            sentences = [sentence.split() for sentence in input_df[\"fall_description\"]]\n",
    "            self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            # self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            # self.tf_idf_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "            self.ngram_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, input_df, y=None, **fit_transform_params):\n",
    "        self.fit(input_df)\n",
    "        return self.transform(input_df)\n",
    "\n",
    "    def pos_tagger_func(self, row):\n",
    "        fall_description = row[\"fall_description\"]\n",
    "        word_tokens = word_tokenize(fall_description)\n",
    "        tagged_words = pos_tag(word_tokens)\n",
    "        list_of_tags = [tag[1] for tag in tagged_words] # Just get list of tags\n",
    "        # The POS tagger has a lot of possible tags, but since we don't want to increase dimensionality too much, we will condense this a bit\n",
    "        # Inspiration taken from https://betterprogramming.pub/beginners-to-advanced-feature-engineering-from-text-data-c228047a4813\n",
    "        noun_count = 0\n",
    "        pronoun_count = 0\n",
    "        verb_count = 0\n",
    "        adj_count = 0\n",
    "        numeric_count = 0\n",
    "        \n",
    "        for tag in list_of_tags:\n",
    "            if tag in ['NN','NNP','NNS']:\n",
    "                noun_count += 1\n",
    "            elif tag in ['PRP','PRP$']:\n",
    "                pronoun_count += 1\n",
    "            elif tag in ['VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "                verb_count += 1\n",
    "            elif tag in ['JJ','JJR','JJS']:\n",
    "                adj_count += 1\n",
    "            elif tag in ['CD']:\n",
    "                numeric_count += 1\n",
    "            # Not including else for other annotations because then it could throw the model training off track\n",
    "        return pd.Series([noun_count / len(list_of_tags), pronoun_count / len(list_of_tags), verb_count / len(list_of_tags), \n",
    "                          adj_count / len(list_of_tags), numeric_count / len(list_of_tags)], \n",
    "                         index=[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"])\n",
    "\n",
    "    def preprocess_text_data(self, text):\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        text = text.lower()\n",
    "        text = ''.join([word for word in text if word not in string.punctuation])\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def vectorize(self, sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [self.word2vec_model.wv[word] for word in words if word in self.word2vec_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "e5e3bda1-0808-4885-a85c-77bb34772952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "ensemble_classifier = VotingClassifier(estimators=[\n",
    "    (\"nb\", make_pipeline(FreezingOfGaitDatasetBuilder_No_TFIDF(preprocess=False), GaussianNB())),\n",
    "    (\"mlp\", make_pipeline(FreezingOfGaitDatasetBuilder_No_TFIDF(preprocess=False), MLPClassifier(alpha=0.0001, learning_rate=\"adaptive\", learning_rate_init=0.001, max_iter=4000, random_state=3))),\n",
    "    (\"knn\", make_pipeline(FreezingOfGaitDatasetBuilder_No_TFIDF(preprocess=False), KNeighborsClassifier(n_neighbors=3, weights='uniform'))),\n",
    "    (\"svc\", make_pipeline(FreezingOfGaitDatasetBuilder_No_TFIDF(preprocess=False), SVC(C=10, kernel=\"sigmoid\", probability=True, random_state=3))),\n",
    "    (\"rf\", make_pipeline(FreezingOfGaitDatasetBuilder_No_TFIDF(preprocess=False), RandomForestClassifier(criterion='entropy', max_depth=7, max_features='sqrt', n_estimators=150, random_state=3))),\n",
    "    (\"lr\", make_pipeline(FreezingOfGaitDatasetBuilder_No_TFIDF(preprocess=False), LogisticRegression(C=0.01, max_iter=5000, penalty='l2', solver='saga', random_state=3)))\n",
    "    ], voting='soft')\n",
    "\n",
    "ensemble_classifier.fit(train_data, y_train)\n",
    "\n",
    "y_pred = ensemble_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_ensemble = f1_score(y_test, y_pred, average=\"micro\")\n",
    "print(micro_f1_score_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ffbc1259-a0e7-4622-b9ff-78f395b88828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a custom \"classifier\" to handle data transformation... this is required so there is no train/test leakage through vectorized text\n",
    "# This will be put through a scikit-learn pipeline, which allows it to be used correctly with a hyperparameter search and cross validation\n",
    "class FreezingOfGaitDatasetBuilder_No_Ngrams():\n",
    "    def __init__(self, preprocess=True):\n",
    "        self.tf_idf_vectorizer = None\n",
    "        # self.ngram_vectorizer = None\n",
    "        self.word2vec_model = None\n",
    "        self.preprocess = preprocess\n",
    "    \n",
    "    def transform(self, input_df, **transform_params):\n",
    "        word_embeddings = None\n",
    "        new_tfidf_data = None\n",
    "        # new_ngram_data = None\n",
    "        \n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "        \n",
    "            # Word2Vec data\n",
    "            word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df_new])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            new_tfidf_data = self.tf_idf_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            # new_ngram_data = self.ngram_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "\n",
    "        else:\n",
    "            # Word2Vec data\n",
    "            word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df[\"fall_description\"]])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            new_tfidf_data = self.tf_idf_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            # new_ngram_data = self.ngram_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "\n",
    "        # Number of characters data\n",
    "        input_df['num_characters'] = input_df.apply(lambda row : len(row[\"fall_description\"]), axis = 1)\n",
    "        num_chars = input_df['num_characters'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # Average length of words data\n",
    "        input_df['avg_word_length'] = input_df.apply(lambda row: np.mean([len(word) for word in row[\"fall_description\"].split()]), axis=1)\n",
    "        avg_length = input_df['avg_word_length'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # Parts of speech data\n",
    "        pos_tag_counts = input_df.apply(lambda row: self.pos_tagger_func(row), axis = 1)\n",
    "        pos_tag_array = pos_tag_counts[[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"]].to_numpy()\n",
    "    \n",
    "        pre_finalized_data = np.hstack((word_embeddings, new_tfidf_data, num_chars, avg_length, pos_tag_array))\n",
    "        standard_scaler = StandardScaler()\n",
    "        finalized_data = standard_scaler.fit_transform(pre_finalized_data)\n",
    "        return finalized_data\n",
    "    \n",
    "    def fit(self, input_df, y=None, **fit_params):\n",
    "        sentences = None\n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "            sentences = [sentence.split() for sentence in input_df_new]\n",
    "            self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            # self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            self.tf_idf_vectorizer.fit(input_df_new.to_numpy())\n",
    "            # self.ngram_vectorizer.fit(input_df_new.to_numpy())\n",
    "        else:\n",
    "            sentences = [sentence.split() for sentence in input_df[\"fall_description\"]]\n",
    "            self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            # self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            self.tf_idf_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "            # self.ngram_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, input_df, y=None, **fit_transform_params):\n",
    "        self.fit(input_df)\n",
    "        return self.transform(input_df)\n",
    "\n",
    "    def pos_tagger_func(self, row):\n",
    "        fall_description = row[\"fall_description\"]\n",
    "        word_tokens = word_tokenize(fall_description)\n",
    "        tagged_words = pos_tag(word_tokens)\n",
    "        list_of_tags = [tag[1] for tag in tagged_words] # Just get list of tags\n",
    "        # The POS tagger has a lot of possible tags, but since we don't want to increase dimensionality too much, we will condense this a bit\n",
    "        # Inspiration taken from https://betterprogramming.pub/beginners-to-advanced-feature-engineering-from-text-data-c228047a4813\n",
    "        noun_count = 0\n",
    "        pronoun_count = 0\n",
    "        verb_count = 0\n",
    "        adj_count = 0\n",
    "        numeric_count = 0\n",
    "        \n",
    "        for tag in list_of_tags:\n",
    "            if tag in ['NN','NNP','NNS']:\n",
    "                noun_count += 1\n",
    "            elif tag in ['PRP','PRP$']:\n",
    "                pronoun_count += 1\n",
    "            elif tag in ['VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "                verb_count += 1\n",
    "            elif tag in ['JJ','JJR','JJS']:\n",
    "                adj_count += 1\n",
    "            elif tag in ['CD']:\n",
    "                numeric_count += 1\n",
    "            # Not including else for other annotations because then it could throw the model training off track\n",
    "        return pd.Series([noun_count / len(list_of_tags), pronoun_count / len(list_of_tags), verb_count / len(list_of_tags), \n",
    "                          adj_count / len(list_of_tags), numeric_count / len(list_of_tags)], \n",
    "                         index=[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"])\n",
    "\n",
    "    def preprocess_text_data(self, text):\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        text = text.lower()\n",
    "        text = ''.join([word for word in text if word not in string.punctuation])\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def vectorize(self, sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [self.word2vec_model.wv[word] for word in words if word in self.word2vec_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "b3eab948-f3ae-4b7a-8c0d-9f8b643c25df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7971014492753623\n"
     ]
    }
   ],
   "source": [
    "ensemble_classifier = VotingClassifier(estimators=[\n",
    "    (\"nb\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Ngrams(preprocess=False), GaussianNB())),\n",
    "    (\"mlp\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Ngrams(preprocess=False), MLPClassifier(alpha=0.0001, learning_rate=\"adaptive\", learning_rate_init=0.001, max_iter=4000, random_state=3))),\n",
    "    (\"knn\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Ngrams(preprocess=False), KNeighborsClassifier(n_neighbors=3, weights='uniform'))),\n",
    "    (\"svc\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Ngrams(preprocess=False), SVC(C=10, kernel=\"sigmoid\", probability=True, random_state=3))),\n",
    "    (\"rf\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Ngrams(preprocess=False), RandomForestClassifier(criterion='entropy', max_depth=7, max_features='sqrt', n_estimators=150, random_state=3))),\n",
    "    (\"lr\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Ngrams(preprocess=False), LogisticRegression(C=0.01, max_iter=5000, penalty='l2', solver='saga', random_state=3)))\n",
    "    ], voting='soft')\n",
    "\n",
    "ensemble_classifier.fit(train_data, y_train)\n",
    "\n",
    "y_pred = ensemble_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_ensemble = f1_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "print(micro_f1_score_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "ecf88f97-0643-44c8-ac2e-7ee98025e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a custom \"classifier\" to handle data transformation... this is required so there is no train/test leakage through vectorized text\n",
    "# This will be put through a scikit-learn pipeline, which allows it to be used correctly with a hyperparameter search and cross validation\n",
    "class FreezingOfGaitDatasetBuilder_No_Word2Vec():\n",
    "    def __init__(self, preprocess=True):\n",
    "        self.tf_idf_vectorizer = None\n",
    "        self.ngram_vectorizer = None\n",
    "        # self.word2vec_model = None\n",
    "        self.preprocess = preprocess\n",
    "    \n",
    "    def transform(self, input_df, **transform_params):\n",
    "        # word_embeddings = None\n",
    "        new_tfidf_data = None\n",
    "        new_ngram_data = None\n",
    "        \n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "        \n",
    "            # Word2Vec data\n",
    "            # word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df_new])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            new_tfidf_data = self.tf_idf_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            new_ngram_data = self.ngram_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "\n",
    "        else:\n",
    "            # Word2Vec data\n",
    "            # word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df[\"fall_description\"]])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            new_tfidf_data = self.tf_idf_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            new_ngram_data = self.ngram_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "\n",
    "        # Number of characters data\n",
    "        input_df['num_characters'] = input_df.apply(lambda row : len(row[\"fall_description\"]), axis = 1)\n",
    "        num_chars = input_df['num_characters'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # Average length of words data\n",
    "        input_df['avg_word_length'] = input_df.apply(lambda row: np.mean([len(word) for word in row[\"fall_description\"].split()]), axis=1)\n",
    "        avg_length = input_df['avg_word_length'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # Parts of speech data\n",
    "        pos_tag_counts = input_df.apply(lambda row: self.pos_tagger_func(row), axis = 1)\n",
    "        pos_tag_array = pos_tag_counts[[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"]].to_numpy()\n",
    "    \n",
    "        pre_finalized_data = np.hstack((new_tfidf_data, new_ngram_data, num_chars, avg_length, pos_tag_array))\n",
    "        standard_scaler = StandardScaler()\n",
    "        finalized_data = standard_scaler.fit_transform(pre_finalized_data)\n",
    "        return finalized_data\n",
    "    \n",
    "    def fit(self, input_df, y=None, **fit_params):\n",
    "        sentences = None\n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "            sentences = [sentence.split() for sentence in input_df_new]\n",
    "            # self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            self.tf_idf_vectorizer.fit(input_df_new.to_numpy())\n",
    "            self.ngram_vectorizer.fit(input_df_new.to_numpy())\n",
    "        else:\n",
    "            sentences = [sentence.split() for sentence in input_df[\"fall_description\"]]\n",
    "            # self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            self.tf_idf_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "            self.ngram_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, input_df, y=None, **fit_transform_params):\n",
    "        self.fit(input_df)\n",
    "        return self.transform(input_df)\n",
    "\n",
    "    def pos_tagger_func(self, row):\n",
    "        fall_description = row[\"fall_description\"]\n",
    "        word_tokens = word_tokenize(fall_description)\n",
    "        tagged_words = pos_tag(word_tokens)\n",
    "        list_of_tags = [tag[1] for tag in tagged_words] # Just get list of tags\n",
    "        # The POS tagger has a lot of possible tags, but since we don't want to increase dimensionality too much, we will condense this a bit\n",
    "        # Inspiration taken from https://betterprogramming.pub/beginners-to-advanced-feature-engineering-from-text-data-c228047a4813\n",
    "        noun_count = 0\n",
    "        pronoun_count = 0\n",
    "        verb_count = 0\n",
    "        adj_count = 0\n",
    "        numeric_count = 0\n",
    "        \n",
    "        for tag in list_of_tags:\n",
    "            if tag in ['NN','NNP','NNS']:\n",
    "                noun_count += 1\n",
    "            elif tag in ['PRP','PRP$']:\n",
    "                pronoun_count += 1\n",
    "            elif tag in ['VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "                verb_count += 1\n",
    "            elif tag in ['JJ','JJR','JJS']:\n",
    "                adj_count += 1\n",
    "            elif tag in ['CD']:\n",
    "                numeric_count += 1\n",
    "            # Not including else for other annotations because then it could throw the model training off track\n",
    "        return pd.Series([noun_count / len(list_of_tags), pronoun_count / len(list_of_tags), verb_count / len(list_of_tags), \n",
    "                          adj_count / len(list_of_tags), numeric_count / len(list_of_tags)], \n",
    "                         index=[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"])\n",
    "\n",
    "    def preprocess_text_data(self, text):\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        text = text.lower()\n",
    "        text = ''.join([word for word in text if word not in string.punctuation])\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    # def vectorize(self, sentence):\n",
    "    #     words = sentence.split()\n",
    "    #     words_vecs = [self.word2vec_model.wv[word] for word in words if word in self.word2vec_model.wv]\n",
    "    #     if len(words_vecs) == 0:\n",
    "    #         return np.zeros(100)\n",
    "    #     words_vecs = np.array(words_vecs)\n",
    "    #     return words_vecs.mean(axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "3df743b0-b631-49e5-bcd5-e7dbcba3ff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8260869565217391\n"
     ]
    }
   ],
   "source": [
    "ensemble_classifier = VotingClassifier(estimators=[\n",
    "    (\"nb\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Word2Vec(preprocess=False), GaussianNB())),\n",
    "    (\"mlp\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Word2Vec(preprocess=False), MLPClassifier(alpha=0.0001, learning_rate=\"adaptive\", learning_rate_init=0.001, max_iter=4000, random_state=3))),\n",
    "    (\"knn\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Word2Vec(preprocess=False), KNeighborsClassifier(n_neighbors=3, weights='uniform'))),\n",
    "    (\"svc\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Word2Vec(preprocess=False), SVC(C=10, kernel=\"sigmoid\", probability=True, random_state=3))),\n",
    "    (\"rf\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Word2Vec(preprocess=False), RandomForestClassifier(criterion='entropy', max_depth=7, max_features='sqrt', n_estimators=150, random_state=3))),\n",
    "    (\"lr\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Word2Vec(preprocess=False), LogisticRegression(C=0.01, max_iter=5000, penalty='l2', solver='saga', random_state=3)))\n",
    "    ], voting='soft')\n",
    "\n",
    "ensemble_classifier.fit(train_data, y_train)\n",
    "\n",
    "y_pred = ensemble_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_ensemble = f1_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "print(micro_f1_score_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "d92db3a3-f91c-4a7b-82eb-f64b41585a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a custom \"classifier\" to handle data transformation... this is required so there is no train/test leakage through vectorized text\n",
    "# This will be put through a scikit-learn pipeline, which allows it to be used correctly with a hyperparameter search and cross validation\n",
    "class FreezingOfGaitDatasetBuilder_No_POSTagging():\n",
    "    def __init__(self, preprocess=True):\n",
    "        self.tf_idf_vectorizer = None\n",
    "        self.ngram_vectorizer = None\n",
    "        self.word2vec_model = None\n",
    "        self.preprocess = preprocess\n",
    "    \n",
    "    def transform(self, input_df, **transform_params):\n",
    "        word_embeddings = None\n",
    "        new_tfidf_data = None\n",
    "        new_ngram_data = None\n",
    "        \n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "        \n",
    "            # Word2Vec data\n",
    "            word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df_new])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            new_tfidf_data = self.tf_idf_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            new_ngram_data = self.ngram_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "\n",
    "        else:\n",
    "            # Word2Vec data\n",
    "            word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df[\"fall_description\"]])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            new_tfidf_data = self.tf_idf_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            new_ngram_data = self.ngram_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "\n",
    "        # Number of characters data\n",
    "        input_df['num_characters'] = input_df.apply(lambda row : len(row[\"fall_description\"]), axis = 1)\n",
    "        num_chars = input_df['num_characters'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # Average length of words data\n",
    "        input_df['avg_word_length'] = input_df.apply(lambda row: np.mean([len(word) for word in row[\"fall_description\"].split()]), axis=1)\n",
    "        avg_length = input_df['avg_word_length'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # # Parts of speech data\n",
    "        # pos_tag_counts = input_df.apply(lambda row: self.pos_tagger_func(row), axis = 1)\n",
    "        # pos_tag_array = pos_tag_counts[[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"]].to_numpy()\n",
    "    \n",
    "        pre_finalized_data = np.hstack((word_embeddings, new_tfidf_data, new_ngram_data, num_chars, avg_length))\n",
    "        standard_scaler = StandardScaler()\n",
    "        finalized_data = standard_scaler.fit_transform(pre_finalized_data)\n",
    "        return finalized_data\n",
    "    \n",
    "    def fit(self, input_df, y=None, **fit_params):\n",
    "        sentences = None\n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "            sentences = [sentence.split() for sentence in input_df_new]\n",
    "            self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            self.tf_idf_vectorizer.fit(input_df_new.to_numpy())\n",
    "            self.ngram_vectorizer.fit(input_df_new.to_numpy())\n",
    "        else:\n",
    "            sentences = [sentence.split() for sentence in input_df[\"fall_description\"]]\n",
    "            self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            self.tf_idf_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "            self.ngram_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, input_df, y=None, **fit_transform_params):\n",
    "        self.fit(input_df)\n",
    "        return self.transform(input_df)\n",
    "\n",
    "    # def pos_tagger_func(self, row):\n",
    "    #     fall_description = row[\"fall_description\"]\n",
    "    #     word_tokens = word_tokenize(fall_description)\n",
    "    #     tagged_words = pos_tag(word_tokens)\n",
    "    #     list_of_tags = [tag[1] for tag in tagged_words] # Just get list of tags\n",
    "    #     # The POS tagger has a lot of possible tags, but since we don't want to increase dimensionality too much, we will condense this a bit\n",
    "    #     # Inspiration taken from https://betterprogramming.pub/beginners-to-advanced-feature-engineering-from-text-data-c228047a4813\n",
    "    #     noun_count = 0\n",
    "    #     pronoun_count = 0\n",
    "    #     verb_count = 0\n",
    "    #     adj_count = 0\n",
    "    #     numeric_count = 0\n",
    "        \n",
    "    #     for tag in list_of_tags:\n",
    "    #         if tag in ['NN','NNP','NNS']:\n",
    "    #             noun_count += 1\n",
    "    #         elif tag in ['PRP','PRP$']:\n",
    "    #             pronoun_count += 1\n",
    "    #         elif tag in ['VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "    #             verb_count += 1\n",
    "    #         elif tag in ['JJ','JJR','JJS']:\n",
    "    #             adj_count += 1\n",
    "    #         elif tag in ['CD']:\n",
    "    #             numeric_count += 1\n",
    "    #         # Not including else for other annotations because then it could throw the model training off track\n",
    "    #     return pd.Series([noun_count / len(list_of_tags), pronoun_count / len(list_of_tags), verb_count / len(list_of_tags), \n",
    "    #                       adj_count / len(list_of_tags), numeric_count / len(list_of_tags)], \n",
    "    #                      index=[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"])\n",
    "\n",
    "    def preprocess_text_data(self, text):\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        text = text.lower()\n",
    "        text = ''.join([word for word in text if word not in string.punctuation])\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def vectorize(self, sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [self.word2vec_model.wv[word] for word in words if word in self.word2vec_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b4a947a3-63a5-455c-a65b-4fbbd50f08d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8115942028985508\n"
     ]
    }
   ],
   "source": [
    "ensemble_classifier = VotingClassifier(estimators=[\n",
    "    (\"nb\", make_pipeline(FreezingOfGaitDatasetBuilder_No_POSTagging(preprocess=False), GaussianNB())),\n",
    "    (\"mlp\", make_pipeline(FreezingOfGaitDatasetBuilder_No_POSTagging(preprocess=False), MLPClassifier(alpha=0.0001, learning_rate=\"adaptive\", learning_rate_init=0.001, max_iter=4000, random_state=3))),\n",
    "    (\"knn\", make_pipeline(FreezingOfGaitDatasetBuilder_No_POSTagging(preprocess=False), KNeighborsClassifier(n_neighbors=3, weights='uniform'))),\n",
    "    (\"svc\", make_pipeline(FreezingOfGaitDatasetBuilder_No_POSTagging(preprocess=False), SVC(C=10, kernel=\"sigmoid\", probability=True, random_state=3))),\n",
    "    (\"rf\", make_pipeline(FreezingOfGaitDatasetBuilder_No_POSTagging(preprocess=False), RandomForestClassifier(criterion='entropy', max_depth=7, max_features='sqrt', n_estimators=150, random_state=3))),\n",
    "    (\"lr\", make_pipeline(FreezingOfGaitDatasetBuilder_No_POSTagging(preprocess=False), LogisticRegression(C=0.01, max_iter=5000, penalty='l2', solver='saga', random_state=3)))\n",
    "    ], voting='soft')\n",
    "\n",
    "ensemble_classifier.fit(train_data, y_train)\n",
    "\n",
    "y_pred = ensemble_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_ensemble = f1_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "print(micro_f1_score_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a68d0620-100a-4233-a0a7-89cbbb6bd222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a custom \"classifier\" to handle data transformation... this is required so there is no train/test leakage through vectorized text\n",
    "# This will be put through a scikit-learn pipeline, which allows it to be used correctly with a hyperparameter search and cross validation\n",
    "class FreezingOfGaitDatasetBuilder_No_Number_Characters():\n",
    "    def __init__(self, preprocess=True):\n",
    "        self.tf_idf_vectorizer = None\n",
    "        self.ngram_vectorizer = None\n",
    "        self.word2vec_model = None\n",
    "        self.preprocess = preprocess\n",
    "    \n",
    "    def transform(self, input_df, **transform_params):\n",
    "        word_embeddings = None\n",
    "        new_tfidf_data = None\n",
    "        new_ngram_data = None\n",
    "        \n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "        \n",
    "            # Word2Vec data\n",
    "            word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df_new])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            new_tfidf_data = self.tf_idf_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            new_ngram_data = self.ngram_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "\n",
    "        else:\n",
    "            # Word2Vec data\n",
    "            word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df[\"fall_description\"]])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            new_tfidf_data = self.tf_idf_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            new_ngram_data = self.ngram_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "\n",
    "        # # Number of characters data\n",
    "        # input_df['num_characters'] = input_df.apply(lambda row : len(row[\"fall_description\"]), axis = 1)\n",
    "        # num_chars = input_df['num_characters'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # Average length of words data\n",
    "        input_df['avg_word_length'] = input_df.apply(lambda row: np.mean([len(word) for word in row[\"fall_description\"].split()]), axis=1)\n",
    "        avg_length = input_df['avg_word_length'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # Parts of speech data\n",
    "        pos_tag_counts = input_df.apply(lambda row: self.pos_tagger_func(row), axis = 1)\n",
    "        pos_tag_array = pos_tag_counts[[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"]].to_numpy()\n",
    "    \n",
    "        pre_finalized_data = np.hstack((word_embeddings, new_tfidf_data, new_ngram_data, avg_length, pos_tag_array))\n",
    "        standard_scaler = StandardScaler()\n",
    "        finalized_data = standard_scaler.fit_transform(pre_finalized_data)\n",
    "        return finalized_data\n",
    "    \n",
    "    def fit(self, input_df, y=None, **fit_params):\n",
    "        sentences = None\n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "            sentences = [sentence.split() for sentence in input_df_new]\n",
    "            self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            self.tf_idf_vectorizer.fit(input_df_new.to_numpy())\n",
    "            self.ngram_vectorizer.fit(input_df_new.to_numpy())\n",
    "        else:\n",
    "            sentences = [sentence.split() for sentence in input_df[\"fall_description\"]]\n",
    "            self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            self.tf_idf_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "            self.ngram_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, input_df, y=None, **fit_transform_params):\n",
    "        self.fit(input_df)\n",
    "        return self.transform(input_df)\n",
    "\n",
    "    def pos_tagger_func(self, row):\n",
    "        fall_description = row[\"fall_description\"]\n",
    "        word_tokens = word_tokenize(fall_description)\n",
    "        tagged_words = pos_tag(word_tokens)\n",
    "        list_of_tags = [tag[1] for tag in tagged_words] # Just get list of tags\n",
    "        # The POS tagger has a lot of possible tags, but since we don't want to increase dimensionality too much, we will condense this a bit\n",
    "        # Inspiration taken from https://betterprogramming.pub/beginners-to-advanced-feature-engineering-from-text-data-c228047a4813\n",
    "        noun_count = 0\n",
    "        pronoun_count = 0\n",
    "        verb_count = 0\n",
    "        adj_count = 0\n",
    "        numeric_count = 0\n",
    "        \n",
    "        for tag in list_of_tags:\n",
    "            if tag in ['NN','NNP','NNS']:\n",
    "                noun_count += 1\n",
    "            elif tag in ['PRP','PRP$']:\n",
    "                pronoun_count += 1\n",
    "            elif tag in ['VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "                verb_count += 1\n",
    "            elif tag in ['JJ','JJR','JJS']:\n",
    "                adj_count += 1\n",
    "            elif tag in ['CD']:\n",
    "                numeric_count += 1\n",
    "            # Not including else for other annotations because then it could throw the model training off track\n",
    "        return pd.Series([noun_count / len(list_of_tags), pronoun_count / len(list_of_tags), verb_count / len(list_of_tags), \n",
    "                          adj_count / len(list_of_tags), numeric_count / len(list_of_tags)], \n",
    "                         index=[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"])\n",
    "\n",
    "    def preprocess_text_data(self, text):\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        text = text.lower()\n",
    "        text = ''.join([word for word in text if word not in string.punctuation])\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def vectorize(self, sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [self.word2vec_model.wv[word] for word in words if word in self.word2vec_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "8049c54e-5c4b-49b6-baff-fb3aaf88a8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8260869565217391\n"
     ]
    }
   ],
   "source": [
    "ensemble_classifier = VotingClassifier(estimators=[\n",
    "    (\"nb\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Number_Characters(preprocess=False), GaussianNB())),\n",
    "    (\"mlp\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Number_Characters(preprocess=False), MLPClassifier(alpha=0.0001, learning_rate=\"adaptive\", learning_rate_init=0.001, max_iter=4000, random_state=3))),\n",
    "    (\"knn\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Number_Characters(preprocess=False), KNeighborsClassifier(n_neighbors=3, weights='uniform'))),\n",
    "    (\"svc\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Number_Characters(preprocess=False), SVC(C=10, kernel=\"sigmoid\", probability=True, random_state=3))),\n",
    "    (\"rf\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Number_Characters(preprocess=False), RandomForestClassifier(criterion='entropy', max_depth=7, max_features='sqrt', n_estimators=150, random_state=3))),\n",
    "    (\"lr\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Number_Characters(preprocess=False), LogisticRegression(C=0.01, max_iter=5000, penalty='l2', solver='saga', random_state=3)))\n",
    "    ], voting='soft')\n",
    "\n",
    "ensemble_classifier.fit(train_data, y_train)\n",
    "\n",
    "y_pred = ensemble_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_ensemble = f1_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "print(micro_f1_score_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "a525495b-27e4-4e65-ac60-5a77f9ac2ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a custom \"classifier\" to handle data transformation... this is required so there is no train/test leakage through vectorized text\n",
    "# This will be put through a scikit-learn pipeline, which allows it to be used correctly with a hyperparameter search and cross validation\n",
    "class FreezingOfGaitDatasetBuilder_No_Avg_Length():\n",
    "    def __init__(self, preprocess=True):\n",
    "        self.tf_idf_vectorizer = None\n",
    "        self.ngram_vectorizer = None\n",
    "        self.word2vec_model = None\n",
    "        self.preprocess = preprocess\n",
    "    \n",
    "    def transform(self, input_df, **transform_params):\n",
    "        word_embeddings = None\n",
    "        new_tfidf_data = None\n",
    "        new_ngram_data = None\n",
    "        \n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "        \n",
    "            # Word2Vec data\n",
    "            word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df_new])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            new_tfidf_data = self.tf_idf_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            new_ngram_data = self.ngram_vectorizer.transform(input_df_new.to_numpy()).toarray()\n",
    "\n",
    "        else:\n",
    "            # Word2Vec data\n",
    "            word_embeddings = np.array([self.vectorize(sentence) for sentence in input_df[\"fall_description\"]])\n",
    "            \n",
    "            # TF-IDF data\n",
    "            new_tfidf_data = self.tf_idf_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "    \n",
    "            # N-gram data\n",
    "            new_ngram_data = self.ngram_vectorizer.transform(input_df[\"fall_description\"].to_numpy()).toarray()\n",
    "\n",
    "        # Number of characters data\n",
    "        input_df['num_characters'] = input_df.apply(lambda row : len(row[\"fall_description\"]), axis = 1)\n",
    "        num_chars = input_df['num_characters'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # # Average length of words data\n",
    "        # input_df['avg_word_length'] = input_df.apply(lambda row: np.mean([len(word) for word in row[\"fall_description\"].split()]), axis=1)\n",
    "        # avg_length = input_df['avg_word_length'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "        # Parts of speech data\n",
    "        pos_tag_counts = input_df.apply(lambda row: self.pos_tagger_func(row), axis = 1)\n",
    "        pos_tag_array = pos_tag_counts[[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"]].to_numpy()\n",
    "    \n",
    "        pre_finalized_data = np.hstack((word_embeddings, new_tfidf_data, new_ngram_data, num_chars, pos_tag_array))\n",
    "        standard_scaler = StandardScaler()\n",
    "        finalized_data = standard_scaler.fit_transform(pre_finalized_data)\n",
    "        return finalized_data\n",
    "    \n",
    "    def fit(self, input_df, y=None, **fit_params):\n",
    "        sentences = None\n",
    "        if self.preprocess == True:\n",
    "            input_df_new = input_df[\"fall_description\"].apply(self.preprocess_text_data)\n",
    "            sentences = [sentence.split() for sentence in input_df_new]\n",
    "            self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            self.tf_idf_vectorizer.fit(input_df_new.to_numpy())\n",
    "            self.ngram_vectorizer.fit(input_df_new.to_numpy())\n",
    "        else:\n",
    "            sentences = [sentence.split() for sentence in input_df[\"fall_description\"]]\n",
    "            self.word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5)\n",
    "            \n",
    "            self.tf_idf_vectorizer = TfidfVectorizer()\n",
    "            self.ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "            \n",
    "            self.tf_idf_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "            self.ngram_vectorizer.fit(input_df[\"fall_description\"].to_numpy())\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, input_df, y=None, **fit_transform_params):\n",
    "        self.fit(input_df)\n",
    "        return self.transform(input_df)\n",
    "\n",
    "    def pos_tagger_func(self, row):\n",
    "        fall_description = row[\"fall_description\"]\n",
    "        word_tokens = word_tokenize(fall_description)\n",
    "        tagged_words = pos_tag(word_tokens)\n",
    "        list_of_tags = [tag[1] for tag in tagged_words] # Just get list of tags\n",
    "        # The POS tagger has a lot of possible tags, but since we don't want to increase dimensionality too much, we will condense this a bit\n",
    "        # Inspiration taken from https://betterprogramming.pub/beginners-to-advanced-feature-engineering-from-text-data-c228047a4813\n",
    "        noun_count = 0\n",
    "        pronoun_count = 0\n",
    "        verb_count = 0\n",
    "        adj_count = 0\n",
    "        numeric_count = 0\n",
    "        \n",
    "        for tag in list_of_tags:\n",
    "            if tag in ['NN','NNP','NNS']:\n",
    "                noun_count += 1\n",
    "            elif tag in ['PRP','PRP$']:\n",
    "                pronoun_count += 1\n",
    "            elif tag in ['VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "                verb_count += 1\n",
    "            elif tag in ['JJ','JJR','JJS']:\n",
    "                adj_count += 1\n",
    "            elif tag in ['CD']:\n",
    "                numeric_count += 1\n",
    "            # Not including else for other annotations because then it could throw the model training off track\n",
    "        return pd.Series([noun_count / len(list_of_tags), pronoun_count / len(list_of_tags), verb_count / len(list_of_tags), \n",
    "                          adj_count / len(list_of_tags), numeric_count / len(list_of_tags)], \n",
    "                         index=[\"Nouns\", \"Pronouns\", \"Verbs\", \"Adjectives\", \"Numerics\"])\n",
    "\n",
    "    def preprocess_text_data(self, text):\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        text = text.lower()\n",
    "        text = ''.join([word for word in text if word not in string.punctuation])\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def vectorize(self, sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [self.word2vec_model.wv[word] for word in words if word in self.word2vec_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "e40fa317-ef3c-4f9c-96ad-527d53d79abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8115942028985508\n"
     ]
    }
   ],
   "source": [
    "ensemble_classifier = VotingClassifier(estimators=[\n",
    "    (\"nb\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Avg_Length(preprocess=False), GaussianNB())),\n",
    "    (\"mlp\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Avg_Length(preprocess=False), MLPClassifier(alpha=0.0001, learning_rate=\"adaptive\", learning_rate_init=0.001, max_iter=4000, random_state=3))),\n",
    "    (\"knn\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Avg_Length(preprocess=False), KNeighborsClassifier(n_neighbors=3, weights='uniform'))),\n",
    "    (\"svc\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Avg_Length(preprocess=False), SVC(C=10, kernel=\"sigmoid\", probability=True, random_state=3))),\n",
    "    (\"rf\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Avg_Length(preprocess=False), RandomForestClassifier(criterion='entropy', max_depth=7, max_features='sqrt', n_estimators=150, random_state=3))),\n",
    "    (\"lr\", make_pipeline(FreezingOfGaitDatasetBuilder_No_Avg_Length(preprocess=False), LogisticRegression(C=0.01, max_iter=5000, penalty='l2', solver='saga', random_state=3)))\n",
    "    ], voting='soft')\n",
    "\n",
    "ensemble_classifier.fit(train_data, y_train)\n",
    "\n",
    "y_pred = ensemble_classifier.predict(test_data)\n",
    "\n",
    "micro_f1_score_ensemble = f1_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "print(micro_f1_score_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47e6c4-a550-4d52-99de-831d5f4703cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
